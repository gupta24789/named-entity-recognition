{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gupta24789/named-entity-recognition/blob/main/ner_cnnchar_lstm_crf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzgdseInlU0n"
      },
      "outputs": [],
      "source": [
        "# !wget https://nlp.stanford.edu/data/glove.6B.zip\n",
        "# !unzip glove.6B.zip -d embeddings/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_DVWM-IlU0q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLgCUdUDlU0r"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import itertools\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "from pprint import pprint\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchmetrics\n",
        "from torch import optim\n",
        "import torch.autograd as autograd\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from seqeval import metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyuWqBIqlU0s"
      },
      "source": [
        "## Download Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T__HYJwLlU0u"
      },
      "outputs": [],
      "source": [
        "# Path('data/train').mkdir(parents = True, exist_ok= True)\n",
        "# Path('data/val').mkdir(parents = True, exist_ok= True)\n",
        "# Path('data/test').mkdir(parents = True, exist_ok= True)\n",
        "\n",
        "# os.system(\"cd data/train && wget https://raw.githubusercontent.com/gupta24789/named-entity-recognition/main/data/train/sentences.txt\")\n",
        "# os.system(\"cd data/train && wget https://raw.githubusercontent.com/gupta24789/named-entity-recognition/main/data/train/labels.txt\")\n",
        "# os.system(\"cd data/val && wget https://raw.githubusercontent.com/gupta24789/named-entity-recognition/main/data/val/sentences.txt\")\n",
        "# os.system(\"cd data/val && wget https://raw.githubusercontent.com/gupta24789/named-entity-recognition/main/data/val/labels.txt\")\n",
        "# os.system(\"cd data/test && wget https://raw.githubusercontent.com/gupta24789/named-entity-recognition/main/data/test/sentences.txt\")\n",
        "# os.system(\"cd data/test && wget https://raw.githubusercontent.com/gupta24789/named-entity-recognition/main/data/test/labels.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqji2RXJlU0v"
      },
      "source": [
        "## Set Seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvZ_TKJmlU0w",
        "outputId": "398148e0-35a1-4ce5-c1a2-85d2af38f674"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Seed set to 121\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "121"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "seed = 121\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "pl.seed_everything(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMPyYGAUlU0x"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwgG2kWGlU0y"
      },
      "outputs": [],
      "source": [
        "## train\n",
        "train_sents = open(\"data/train/sentences.txt\",\"r\").readlines()\n",
        "train_tags = open(\"data/train/labels.txt\",\"r\").readlines()\n",
        "## val\n",
        "val_sents = open(\"data/val/sentences.txt\",\"r\").readlines()\n",
        "val_tags = open(\"data/val/labels.txt\",\"r\").readlines()\n",
        "## test\n",
        "test_sents = open(\"data/test/sentences.txt\",\"r\").readlines()\n",
        "test_tags = open(\"data/test/labels.txt\",\"r\").readlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvokgQGAlU0y",
        "outputId": "18fb6ff1-11a4-4f1d-ce07-a8f4e019cfe0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .\\n',\n",
              " 'Families of soldiers killed in the conflict joined the protesters who carried banners with such slogans as \" Bush Number One Terrorist \" and \" Stop the Bombings . \"\\n']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_sents[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9GK9xkyOlU0z",
        "outputId": "8f3de7c2-fda1-4c45-936c-b0917161d00f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['O O O O O O B-geo O O O O O B-geo O O O O O B-gpe O O O O O\\n',\n",
              " 'O O O O O O O O O O O O O O O O O O B-per O O O O O O O O O O O\\n']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_tags[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fj5unuO7lU00"
      },
      "outputs": [],
      "source": [
        "X_train = [sent.strip().split(\" \") for sent in train_sents]\n",
        "y_train = [tag.strip().split(\" \") for tag in train_tags]\n",
        "\n",
        "X_val = [sent.strip().split(\" \") for sent in val_sents]\n",
        "y_val = [tag.strip().split(\" \") for tag in val_tags]\n",
        "\n",
        "X_test = [sent.strip().split(\" \") for sent in test_sents]\n",
        "y_test = [tag.strip().split(\" \") for tag in test_tags]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCKcS_DGlU01",
        "outputId": "31802612-c774-4f44-daba-aab94bbb00e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['Thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'London',\n",
            "  'to', 'protest', 'the', 'war', 'in', 'Iraq', 'and', 'demand', 'the',\n",
            "  'withdrawal', 'of', 'British', 'troops', 'from', 'that', 'country', '.'],\n",
            " ['Families', 'of', 'soldiers', 'killed', 'in', 'the', 'conflict', 'joined',\n",
            "  'the', 'protesters', 'who', 'carried', 'banners', 'with', 'such', 'slogans',\n",
            "  'as', '\"', 'Bush', 'Number', 'One', 'Terrorist', '\"', 'and', '\"', 'Stop',\n",
            "  'the', 'Bombings', '.', '\"']]\n"
          ]
        }
      ],
      "source": [
        "pprint((X_train[:2]), compact=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBFPNG5rlU01",
        "outputId": "3da62446-c44f-459c-c27a-3804bfffde05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O',\n",
            "  'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']]\n"
          ]
        }
      ],
      "source": [
        "pprint(y_train[:1], compact=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uHi-wArlU02"
      },
      "source": [
        "## Create Vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvHAcWFIlU02",
        "outputId": "4700cc1c-43e7-411a-e2e1-9ead3f530770"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Char Vocab : 100\n"
          ]
        }
      ],
      "source": [
        "## char vocab\n",
        "special_words = ['__PAD__','__UNK__']\n",
        "char_vocab = list(set(itertools.chain.from_iterable(X_train + X_val + X_test)))\n",
        "char_vocab = list(set(itertools.chain.from_iterable([list(w) for w in char_vocab])))\n",
        "char_vocab = special_words + char_vocab\n",
        "print(f'Char Vocab : {len(char_vocab)}')\n",
        "\n",
        "char2idx = {char:i for i, char in enumerate(char_vocab)}\n",
        "idx2char = {i:char for char,i in char2idx.items()}\n",
        "\n",
        "CHAR_UNK_ID = char2idx['__UNK__']\n",
        "CHAR_PAD_ID = char2idx['__PAD__']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zR5EXQTnlU03",
        "outputId": "76d9b4d8-beb3-4299-93e9-250b080dbac1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vocab size : 35180\n",
            "tags : 18\n",
            "{'B-art': 9,\n",
            " 'B-eve': 11,\n",
            " 'B-geo': 10,\n",
            " 'B-gpe': 7,\n",
            " 'B-nat': 8,\n",
            " 'B-org': 16,\n",
            " 'B-per': 6,\n",
            " 'B-tim': 15,\n",
            " 'I-art': 17,\n",
            " 'I-eve': 12,\n",
            " 'I-geo': 14,\n",
            " 'I-gpe': 5,\n",
            " 'I-nat': 4,\n",
            " 'I-org': 1,\n",
            " 'I-per': 2,\n",
            " 'I-tim': 3,\n",
            " 'O': 13,\n",
            " '__PAD__': 0}\n",
            "PAD ID : 0\n"
          ]
        }
      ],
      "source": [
        "special_words = ['__PAD__','__UNK__']\n",
        "vocab = list(set(itertools.chain.from_iterable(X_train + X_val + X_test)))\n",
        "vocab = special_words + vocab\n",
        "word2idx = {w:i for i,w in enumerate(vocab)}\n",
        "idx2word = {i:w for w,i in word2idx.items()}\n",
        "\n",
        "## TAGS\n",
        "tags = list(set(itertools.chain.from_iterable(y_train)))\n",
        "tags = ['__PAD__'] + tags\n",
        "tag2idx = {w:i for i,w in enumerate(tags)}\n",
        "idx2tag = {i:w for w,i in tag2idx.items()}\n",
        "\n",
        "\n",
        "print(f\"vocab size : {len(vocab)}\")\n",
        "print(f\"tags : {len(tag2idx)}\")\n",
        "pprint(tag2idx, compact=True)\n",
        "\n",
        "PAD_ID = word2idx['__PAD__']\n",
        "UNK_ID = word2idx['__UNK__']\n",
        "\n",
        "print(f\"PAD ID : {PAD_ID}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XeLHL49lU03"
      },
      "source": [
        "## Encode sent & tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_B0-iPrlU03"
      },
      "outputs": [],
      "source": [
        "def to_sent_number(sent_list):\n",
        "    encoded = []\n",
        "    for w in sent_list:\n",
        "        encoded.append(word2idx.get(w, UNK_ID))\n",
        "    return encoded\n",
        "\n",
        "\n",
        "def to_tag_number(tag_list):\n",
        "    encoded = []\n",
        "    for tag in tag_list:\n",
        "        encoded.append(tag2idx[tag])\n",
        "    return encoded\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZglia16lU04"
      },
      "outputs": [],
      "source": [
        "def to_char_number(sent_list):\n",
        "    seq_char_list = []\n",
        "    for word in sent_list:\n",
        "        char_list = list(word)\n",
        "        char_id = list()\n",
        "        for char in char_list:\n",
        "            char_id.append(char2idx.get(char, CHAR_UNK_ID))\n",
        "        seq_char_list.append(char_id)\n",
        "    return seq_char_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qDEuFhUlU04"
      },
      "outputs": [],
      "source": [
        "X_train_encoded = [to_sent_number(sent) for sent in X_train]\n",
        "X_train_char_encoded = [to_char_number(sent) for sent in X_train]\n",
        "y_train_encoded = [to_tag_number(tags) for tags in y_train]\n",
        "\n",
        "X_val_encoded = [to_sent_number(sent) for sent in X_val]\n",
        "X_val_char_encoded = [to_char_number(sent) for sent in X_val]\n",
        "y_val_encoded = [to_tag_number(tags) for tags in y_val]\n",
        "\n",
        "X_test_encoded = [to_sent_number(sent) for sent in X_test]\n",
        "X_test_char_encoded = [to_char_number(sent) for sent in X_test]\n",
        "y_test_encoded = [to_tag_number(tags) for tags in y_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kmid_hv0lU05",
        "outputId": "73029f7b-5413-4165-bef4-be2486f49d18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[26712, 34197, 33274, 11587, 21753, 25622, 30270, 6375, 29484, 8734, 34332,\n",
            "  4607, 15481, 18687, 26749, 8734, 22975, 34197, 29366, 31635, 11812, 10530,\n",
            "  30933, 32151],\n",
            " [23800, 34197, 30830, 19378, 4607, 8734, 35019, 23610, 8734, 31310, 2627,\n",
            "  25256, 34769, 8757, 9212, 9076, 16113, 17026, 6945, 13859, 32377, 17675,\n",
            "  17026, 18687, 17026, 16654, 8734, 17523, 32151, 17026]]\n"
          ]
        }
      ],
      "source": [
        "pprint(X_train_encoded[:2], compact=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3tbs0GClU05",
        "outputId": "cdeba8f2-9a97-40f4-8c7f-36c5d9a30901"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[[59, 31, 79, 33, 32, 75, 2, 3, 32], [79, 14],\n",
            "  [3, 20, 88, 79, 2, 32, 71, 21, 75, 71, 79, 21, 32], [31, 75, 81, 20],\n",
            "  [88, 75, 21, 23, 31, 20, 3], [71, 31, 21, 79, 33, 30, 31],\n",
            "  [40, 79, 2, 3, 79, 2], [71, 79], [61, 21, 79, 71, 20, 32, 71], [71, 31, 20],\n",
            "  [91, 75, 21], [13, 2], [97, 21, 75, 48], [75, 2, 3], [3, 20, 88, 75, 2, 3],\n",
            "  [71, 31, 20], [91, 13, 71, 31, 3, 21, 75, 91, 75, 86], [79, 14],\n",
            "  [55, 21, 13, 71, 13, 32, 31], [71, 21, 79, 79, 61, 32], [14, 21, 79, 88],\n",
            "  [71, 31, 75, 71], [23, 79, 33, 2, 71, 21, 73], [45]],\n",
            " [[92, 75, 88, 13, 86, 13, 20, 32], [79, 14], [32, 79, 86, 3, 13, 20, 21, 32],\n",
            "  [83, 13, 86, 86, 20, 3], [13, 2], [71, 31, 20],\n",
            "  [23, 79, 2, 14, 86, 13, 23, 71], [50, 79, 13, 2, 20, 3], [71, 31, 20],\n",
            "  [61, 21, 79, 71, 20, 32, 71, 20, 21, 32], [91, 31, 79],\n",
            "  [23, 75, 21, 21, 13, 20, 3], [96, 75, 2, 2, 20, 21, 32], [91, 13, 71, 31],\n",
            "  [32, 33, 23, 31], [32, 86, 79, 30, 75, 2, 32], [75, 32], [69],\n",
            "  [55, 33, 32, 31], [62, 33, 88, 96, 20, 21], [39, 2, 20],\n",
            "  [59, 20, 21, 21, 79, 21, 13, 32, 71], [69], [75, 2, 3], [69],\n",
            "  [64, 71, 79, 61], [71, 31, 20], [55, 79, 88, 96, 13, 2, 30, 32], [45], [69]]]\n"
          ]
        }
      ],
      "source": [
        "pprint(X_train_char_encoded[:2], compact=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FD0TojdhlU05",
        "outputId": "fc40c5fd-7c7e-43ca-cfff-d077a532ea27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[13, 13, 13, 13, 13, 13, 10, 13, 13, 13, 13, 13, 10, 13, 13, 13, 13, 13, 7, 13,\n",
            "  13, 13, 13, 13],\n",
            " [13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 6, 13,\n",
            "  13, 13, 13, 13, 13, 13, 13, 13, 13, 13]]\n"
          ]
        }
      ],
      "source": [
        "pprint(y_train_encoded[:2], compact=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LU-rlIk4lU06"
      },
      "source": [
        "## Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpzLspi-lU06"
      },
      "outputs": [],
      "source": [
        "def pad_char(chars):\n",
        "    batch_size = len(chars)\n",
        "    max_seq_len = max(map(len, chars))\n",
        "    pad_chars = [chars[idx] + [[0]] * (max_seq_len - len(chars[idx])) for idx in range(len(chars))]\n",
        "    length_list = [list(map(len, pad_char)) for pad_char in pad_chars]\n",
        "    max_word_len = max(map(max, length_list))\n",
        "    char_seq_tensor = torch.zeros((batch_size, max_seq_len, max_word_len)).long()\n",
        "    char_seq_lengths = torch.LongTensor(length_list)\n",
        "    for idx, (seq, seqlen) in enumerate(zip(pad_chars, char_seq_lengths)):\n",
        "        for idy, (word, wordlen) in enumerate(zip(seq, seqlen)):\n",
        "            char_seq_tensor[idx, idy, :wordlen] = torch.LongTensor(word)\n",
        "\n",
        "    return char_seq_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oHsnrYy2lU07"
      },
      "outputs": [],
      "source": [
        "def custom_collate(batch):\n",
        "    sent = [torch.tensor(item[0]) for item in batch]\n",
        "    char_input = [item[1] for item in batch]\n",
        "    tag = [torch.tensor(item[2]) for item in batch]\n",
        "    lengths = torch.tensor([len(item[0]) for item in batch])\n",
        "\n",
        "    padded_sent = nn.utils.rnn.pad_sequence(sent, batch_first=True, padding_value=PAD_ID)\n",
        "    padded_tag = nn.utils.rnn.pad_sequence(tag, batch_first=True, padding_value=PAD_ID)\n",
        "    padded_char = pad_char(char_input)\n",
        "\n",
        "    batch = {\"sent\": padded_sent, \"tag\": padded_tag, \"char\": padded_char, \"lengths\": lengths}\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4b2bExAYlU07"
      },
      "outputs": [],
      "source": [
        "train_dl = DataLoader(list(zip(X_train_encoded,X_train_char_encoded, y_train_encoded)), batch_size = 2, shuffle = False, collate_fn = custom_collate )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zUwEbjUlU07"
      },
      "outputs": [],
      "source": [
        "example = next(iter(train_dl))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TliJpRNblU08",
        "outputId": "2a7db11e-8267-48b1-ba3a-ca869587f429"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([2, 30]),\n",
              " torch.Size([2, 30]),\n",
              " torch.Size([2, 30, 13]),\n",
              " torch.Size([2]))"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example['sent'].shape, example['tag'].shape,  example['char'].shape, example['lengths'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNBZfiRklU08",
        "outputId": "7b23f728-d76a-439f-9e8a-a2f2ceca97f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[26712, 34197, 33274, 11587, 21753, 25622, 30270,  6375, 29484,  8734,\n",
              "         34332,  4607, 15481, 18687, 26749,  8734, 22975, 34197, 29366, 31635,\n",
              "         11812, 10530, 30933, 32151,     0,     0,     0,     0,     0,     0],\n",
              "        [23800, 34197, 30830, 19378,  4607,  8734, 35019, 23610,  8734, 31310,\n",
              "          2627, 25256, 34769,  8757,  9212,  9076, 16113, 17026,  6945, 13859,\n",
              "         32377, 17675, 17026, 18687, 17026, 16654,  8734, 17523, 32151, 17026]])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example['sent']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9jxjpbnlU08",
        "outputId": "b5f7e513-c893-473f-e7b5-96357855438a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[13, 13, 13, 13, 13, 13, 10, 13, 13, 13, 13, 13, 10, 13, 13, 13, 13, 13,\n",
              "          7, 13, 13, 13, 13, 13,  0,  0,  0,  0,  0,  0],\n",
              "        [13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
              "          6, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13]])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example['tag']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytaA9ZHilU09",
        "outputId": "d1853698-463b-4838-f36e-521fffb01370"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[59, 31, 79, 33, 32, 75,  2,  3, 32,  0,  0,  0,  0],\n",
              "         [79, 14,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [ 3, 20, 88, 79,  2, 32, 71, 21, 75, 71, 79, 21, 32],\n",
              "         [31, 75, 81, 20,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [88, 75, 21, 23, 31, 20,  3,  0,  0,  0,  0,  0,  0],\n",
              "         [71, 31, 21, 79, 33, 30, 31,  0,  0,  0,  0,  0,  0],\n",
              "         [40, 79,  2,  3, 79,  2,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [71, 79,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [61, 21, 79, 71, 20, 32, 71,  0,  0,  0,  0,  0,  0],\n",
              "         [71, 31, 20,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [91, 75, 21,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [13,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [97, 21, 75, 48,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [75,  2,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [ 3, 20, 88, 75,  2,  3,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [71, 31, 20,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [91, 13, 71, 31,  3, 21, 75, 91, 75, 86,  0,  0,  0],\n",
              "         [79, 14,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [55, 21, 13, 71, 13, 32, 31,  0,  0,  0,  0,  0,  0],\n",
              "         [71, 21, 79, 79, 61, 32,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [14, 21, 79, 88,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [71, 31, 75, 71,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [23, 79, 33,  2, 71, 21, 73,  0,  0,  0,  0,  0,  0],\n",
              "         [45,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
              "\n",
              "        [[92, 75, 88, 13, 86, 13, 20, 32,  0,  0,  0,  0,  0],\n",
              "         [79, 14,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [32, 79, 86,  3, 13, 20, 21, 32,  0,  0,  0,  0,  0],\n",
              "         [83, 13, 86, 86, 20,  3,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [13,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [71, 31, 20,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [23, 79,  2, 14, 86, 13, 23, 71,  0,  0,  0,  0,  0],\n",
              "         [50, 79, 13,  2, 20,  3,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [71, 31, 20,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [61, 21, 79, 71, 20, 32, 71, 20, 21, 32,  0,  0,  0],\n",
              "         [91, 31, 79,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [23, 75, 21, 21, 13, 20,  3,  0,  0,  0,  0,  0,  0],\n",
              "         [96, 75,  2,  2, 20, 21, 32,  0,  0,  0,  0,  0,  0],\n",
              "         [91, 13, 71, 31,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [32, 33, 23, 31,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [32, 86, 79, 30, 75,  2, 32,  0,  0,  0,  0,  0,  0],\n",
              "         [75, 32,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [69,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [55, 33, 32, 31,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [62, 33, 88, 96, 20, 21,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [39,  2, 20,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [59, 20, 21, 21, 79, 21, 13, 32, 71,  0,  0,  0,  0],\n",
              "         [69,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [75,  2,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [69,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [64, 71, 79, 61,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [71, 31, 20,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [55, 79, 88, 96, 13,  2, 30, 32,  0,  0,  0,  0,  0],\n",
              "         [45,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [69,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]]])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example['char']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RntLyp1XlU09",
        "outputId": "f98a1cf4-211a-4a66-caad-ed3e712db15f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([24, 30])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example['lengths']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsJ56UBwlU09"
      },
      "outputs": [],
      "source": [
        "## dataloaders\n",
        "batch_size = 32\n",
        "train_dl = DataLoader(list(zip(X_train_encoded,X_train_char_encoded, y_train_encoded)), batch_size = batch_size, shuffle = True, collate_fn = custom_collate )\n",
        "val_dl = DataLoader(list(zip(X_val_encoded,X_val_char_encoded, y_val_encoded)), batch_size = batch_size, shuffle = False, collate_fn = custom_collate )\n",
        "test_dl = DataLoader(list(zip(X_test_encoded,X_test_char_encoded,y_test_encoded)), batch_size = batch_size, shuffle = False, collate_fn = custom_collate )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sw3_98jhlU0-"
      },
      "source": [
        "## Pretrained Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jnRwYdKlU0-",
        "outputId": "20a95f25-4f40-4173-cc6f-e3613bbfb25e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_15595/624670142.py:30: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
            "  return torch.tensor(df_list)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([35180, 100])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Pretrained Vectors\n",
        "def load_pretrain_emb(filepath):\n",
        "    lines = open(filepath,\"r\").readlines()\n",
        "    embedd_dict = {}\n",
        "    for line in lines:\n",
        "        if len(line)>0:\n",
        "            tokens = line.strip().split(\" \")\n",
        "            word = tokens[0]\n",
        "            vec = tokens[1:]\n",
        "            vec = np.array(vec).astype(float)\n",
        "            embedd_dict[word]= vec\n",
        "\n",
        "    return embedd_dict\n",
        "\n",
        "def build_pretrain_embedding(filepath, vocab, emb_dim):\n",
        "    embedd_dict = load_pretrain_emb(filepath)\n",
        "\n",
        "    df_list = []\n",
        "\n",
        "    for w,i in vocab.items():\n",
        "        if w in embedd_dict:\n",
        "            df_list.append(torch.tensor(embedd_dict[w]))\n",
        "        elif w.lower() in embedd_dict:\n",
        "            df_list.append(embedd_dict[w.lower()])\n",
        "        else:\n",
        "            random_vec = np.random.normal(size = (emb_dim))\n",
        "            df_list.append(random_vec)\n",
        "\n",
        "\n",
        "    return torch.tensor(df_list)\n",
        "\n",
        "\n",
        "\n",
        "weights = build_pretrain_embedding(\"embeddings/glove.6B.100d.txt\", word2idx, emb_dim=100)\n",
        "weights.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hj5I_kf9lU0-"
      },
      "source": [
        "## CharCNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IVXaIPglU0_"
      },
      "outputs": [],
      "source": [
        "class CharCNN(nn.Module):\n",
        "    def __init__(self, alphabet_size, embedding_dim, hidden_dim, dropout):\n",
        "        super(CharCNN, self).__init__()\n",
        "        print(\"build char sequence feature extractor: CNN ...\")\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.char_drop = nn.Dropout(dropout)\n",
        "        self.char_embeddings = nn.Embedding(alphabet_size, embedding_dim, padding_idx= CHAR_PAD_ID)\n",
        "        self.char_embeddings.weight.data.copy_(torch.from_numpy(CharCNN.random_embedding(alphabet_size, embedding_dim)))\n",
        "        self.char_cnn = nn.Conv1d(embedding_dim, self.hidden_dim, kernel_size=3, padding=1)\n",
        "\n",
        "    @staticmethod\n",
        "    def random_embedding(vocab_size, embedding_dim):\n",
        "        pretrain_emb = np.empty([vocab_size, embedding_dim])\n",
        "        scale = np.sqrt(3.0 / embedding_dim)\n",
        "        for index in range(vocab_size):\n",
        "            pretrain_emb[index, :] = np.random.uniform(-scale, scale, [1, embedding_dim])\n",
        "        pretrain_emb[0, :] = np.zeros((1, embedding_dim))\n",
        "        return pretrain_emb\n",
        "\n",
        "    def forward(self, input):\n",
        "        batch_size = input.size(0)\n",
        "        char_embeds = self.char_drop(self.char_embeddings(input))\n",
        "        ## char_embeds: [batch size, num tokens, num_chars, embedding_dim]\n",
        "        char_embeds = char_embeds[:,:,-1,:]   ## take embedding of last char\n",
        "        ## char_embeds : [batch size, num tokens, embedding_dim]\n",
        "        char_embeds = char_embeds.transpose(2,1)\n",
        "         ## char_embeds : [batch size,  embedding_dim, num tokens,]\n",
        "        char_cnn_out = self.char_cnn(char_embeds)\n",
        "        # char_cnn_out: [batch size, hidden_dim, num tokens]\n",
        "        # char_cnn_out = F.max_pool1d(char_cnn_out, char_cnn_out.size(2),padding = 0)\n",
        "        # print(f\"char_cnn_out : {char_cnn_out.shape}\")\n",
        "        return char_cnn_out.transpose(2,1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iilat6QHlU1N"
      },
      "source": [
        "## CRF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppKs28EilU1N"
      },
      "outputs": [],
      "source": [
        "START_TAG = -2\n",
        "STOP_TAG = -1\n",
        "\n",
        "\n",
        "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
        "def log_sum_exp(vec, m_size):\n",
        "    \"\"\"\n",
        "    calculate log of exp sum\n",
        "    args:\n",
        "        vec (batch_size, vanishing_dim, hidden_dim) : input tensor\n",
        "        m_size : hidden_dim\n",
        "    return:\n",
        "        batch_size, hidden_dim\n",
        "    \"\"\"\n",
        "    _, idx = torch.max(vec, 1)  # B * 1 * M\n",
        "    max_score = torch.gather(vec, 1, idx.view(-1, 1, m_size)).view(-1, 1, m_size)  # B * M\n",
        "    return max_score.view(-1, m_size) + torch.log(torch.sum(torch.exp(vec - max_score.expand_as(vec)), 1)).view(-1,\n",
        "                                                                                                                m_size)  # B * M\n",
        "\n",
        "\n",
        "class CRF(nn.Module):\n",
        "\n",
        "    def __init__(self, tagset_size, gpu):\n",
        "        super(CRF, self).__init__()\n",
        "        print(\"build CRF...\")\n",
        "        self.gpu = gpu\n",
        "        # Matrix of transition parameters.  Entry i,j is the score of transitioning from i to j.\n",
        "        self.tagset_size = tagset_size\n",
        "        # # We add 2 here, because of START_TAG and STOP_TAG\n",
        "        # # transitions (f_tag_size, t_tag_size), transition value from f_tag to t_tag\n",
        "        init_transitions = torch.zeros(self.tagset_size + 2, self.tagset_size + 2)\n",
        "        init_transitions[:, START_TAG] = -10000.0\n",
        "        init_transitions[STOP_TAG, :] = -10000.0\n",
        "        init_transitions[:, 0] = -10000.0\n",
        "        init_transitions[0, :] = -10000.0\n",
        "        # if self.gpu:\n",
        "        #     init_transitions = init_transitions.cuda()\n",
        "        self.transitions = nn.Parameter(init_transitions)\n",
        "\n",
        "        # self.transitions = nn.Parameter(torch.Tensor(self.tagset_size+2, self.tagset_size+2))\n",
        "        # self.transitions.data.zero_()\n",
        "\n",
        "    def _calculate_PZ(self, feats, mask):\n",
        "        \"\"\"\n",
        "            input:\n",
        "                feats: (batch, seq_len, self.tag_size+2)\n",
        "                masks: (batch, seq_len)\n",
        "        \"\"\"\n",
        "        batch_size = feats.size(0)\n",
        "        seq_len = feats.size(1)\n",
        "        tag_size = feats.size(2)\n",
        "        # print feats.view(seq_len, tag_size)\n",
        "        assert (tag_size == self.tagset_size + 2)\n",
        "        mask = mask.transpose(1, 0).contiguous()\n",
        "        ins_num = seq_len * batch_size\n",
        "        ## be careful the view shape, it is .view(ins_num, 1, tag_size) but not .view(ins_num, tag_size, 1)\n",
        "        feats = feats.transpose(1, 0).contiguous().view(ins_num, 1, tag_size).expand(ins_num, tag_size, tag_size)\n",
        "        ## need to consider start\n",
        "        scores = feats + self.transitions.view(1, tag_size, tag_size).expand(ins_num, tag_size, tag_size)\n",
        "        scores = scores.view(seq_len, batch_size, tag_size, tag_size)\n",
        "        # build iter\n",
        "        seq_iter = enumerate(scores)\n",
        "        _, inivalues = next(seq_iter)  # bat_size * from_target_size * to_target_size\n",
        "        # only need start from start_tag\n",
        "        partition = inivalues[:, START_TAG, :].clone().view(batch_size, tag_size, 1)  # bat_size * to_target_size\n",
        "\n",
        "        ## add start score (from start to all tag, duplicate to batch_size)\n",
        "        # partition = partition + self.transitions[START_TAG,:].view(1, tag_size, 1).expand(batch_size, tag_size, 1)\n",
        "        # iter over last scores\n",
        "        for idx, cur_values in seq_iter:\n",
        "            # previous to_target is current from_target\n",
        "            # partition: previous results log(exp(from_target)), #(batch_size * from_target)\n",
        "            # cur_values: bat_size * from_target * to_target\n",
        "\n",
        "            cur_values = cur_values + partition.contiguous().view(batch_size, tag_size, 1).expand(batch_size, tag_size,\n",
        "                                                                                                  tag_size)\n",
        "            cur_partition = log_sum_exp(cur_values, tag_size)\n",
        "            # print cur_partition.data\n",
        "\n",
        "            # (bat_size * from_target * to_target) -> (bat_size * to_target)\n",
        "            # partition = utils.switch(partition, cur_partition, mask[idx].view(bat_size, 1).expand(bat_size, self.tagset_size)).view(bat_size, -1)\n",
        "            mask_idx = mask[idx, :].view(batch_size, 1).expand(batch_size, tag_size)\n",
        "\n",
        "            ## effective updated partition part, only keep the partition value of mask value = 1\n",
        "            masked_cur_partition = cur_partition.masked_select(mask_idx)\n",
        "            ## let mask_idx broadcastable, to disable warning\n",
        "            mask_idx = mask_idx.contiguous().view(batch_size, tag_size, 1)\n",
        "\n",
        "            ## replace the partition where the maskvalue=1, other partition value keeps the same\n",
        "            partition.masked_scatter_(mask_idx, masked_cur_partition)\n",
        "        # until the last state, add transition score for all partition (and do log_sum_exp) then select the value in STOP_TAG\n",
        "        cur_values = self.transitions.view(1, tag_size, tag_size).expand(batch_size, tag_size,\n",
        "                                                                         tag_size) + partition.contiguous().view(\n",
        "            batch_size, tag_size, 1).expand(batch_size, tag_size, tag_size)\n",
        "        cur_partition = log_sum_exp(cur_values, tag_size)\n",
        "        final_partition = cur_partition[:, STOP_TAG]\n",
        "        return final_partition.sum(), scores\n",
        "\n",
        "    def _viterbi_decode(self, feats, mask):\n",
        "        \"\"\"\n",
        "            input:\n",
        "                feats: (batch, seq_len, self.tag_size+2)\n",
        "                mask: (batch, seq_len)\n",
        "            output:\n",
        "                decode_idx: (batch, seq_len) decoded sequence\n",
        "                path_score: (batch, 1) corresponding score for each sequence (to be implementated)\n",
        "        \"\"\"\n",
        "        batch_size = feats.size(0)\n",
        "        seq_len = feats.size(1)\n",
        "        tag_size = feats.size(2)\n",
        "        assert (tag_size == self.tagset_size + 2)\n",
        "        ## calculate sentence length for each sentence\n",
        "        length_mask = torch.sum(mask.long(), dim=1).view(batch_size, 1).long()\n",
        "        ## mask to (seq_len, batch_size)\n",
        "        mask = mask.transpose(1, 0).contiguous()\n",
        "        ins_num = seq_len * batch_size\n",
        "        ## be careful the view shape, it is .view(ins_num, 1, tag_size) but not .view(ins_num, tag_size, 1)\n",
        "        feats = feats.transpose(1, 0).contiguous().view(ins_num, 1, tag_size).expand(ins_num, tag_size, tag_size)\n",
        "        ## need to consider start\n",
        "        scores = feats + self.transitions.view(1, tag_size, tag_size).expand(ins_num, tag_size, tag_size)\n",
        "        scores = scores.view(seq_len, batch_size, tag_size, tag_size)\n",
        "\n",
        "        # build iter\n",
        "        seq_iter = enumerate(scores)\n",
        "        ## record the position of best score\n",
        "        back_points = list()\n",
        "        partition_history = list()\n",
        "        ##  reverse mask (bug for mask = 1- mask, use this as alternative choice)\n",
        "        # mask = 1 + (-1)*mask\n",
        "        mask = (1 - mask.long()).byte()\n",
        "        _, inivalues = next(seq_iter)  # bat_size * from_target_size * to_target_size\n",
        "        # only need start from start_tag\n",
        "        partition = inivalues[:, START_TAG, :].clone().view(batch_size, tag_size)  # bat_size * to_target_size\n",
        "        # print \"init part:\",partition.size()\n",
        "        partition_history.append(partition)\n",
        "        # iter over last scores\n",
        "        for idx, cur_values in seq_iter:\n",
        "            # previous to_target is current from_target\n",
        "            # partition: previous results log(exp(from_target)), #(batch_size * from_target)\n",
        "            # cur_values: batch_size * from_target * to_target\n",
        "            cur_values = cur_values + partition.contiguous().view(batch_size, tag_size, 1).expand(batch_size, tag_size,\n",
        "                                                                                                  tag_size)\n",
        "            ## forscores, cur_bp = torch.max(cur_values[:,:-2,:], 1) # do not consider START_TAG/STOP_TAG\n",
        "            # print \"cur value:\", cur_values.size()\n",
        "            partition, cur_bp = torch.max(cur_values, 1)\n",
        "            # print \"partsize:\",partition.size()\n",
        "            # exit(0)\n",
        "            # print partition\n",
        "            # print cur_bp\n",
        "            # print \"one best, \",idx\n",
        "            partition_history.append(partition)\n",
        "            ## cur_bp: (batch_size, tag_size) max source score position in current tag\n",
        "            ## set padded label as 0, which will be filtered in post processing\n",
        "            cur_bp.masked_fill_(mask[idx].view(batch_size, 1).expand(batch_size, tag_size), 0)\n",
        "            back_points.append(cur_bp)\n",
        "        # exit(0)\n",
        "        ### add score to final STOP_TAG\n",
        "        partition_history = torch.cat(partition_history, 0).view(seq_len, batch_size, -1).transpose(1,\n",
        "                                                                                                    0).contiguous()  ## (batch_size, seq_len. tag_size)\n",
        "        ### get the last position for each setences, and select the last partitions using gather()\n",
        "        last_position = length_mask.view(batch_size, 1, 1).expand(batch_size, 1, tag_size) - 1\n",
        "        last_partition = torch.gather(partition_history, 1, last_position).view(batch_size, tag_size, 1)\n",
        "        ### calculate the score from last partition to end state (and then select the STOP_TAG from it)\n",
        "        last_values = last_partition.expand(batch_size, tag_size, tag_size) + self.transitions.view(1, tag_size,\n",
        "                                                                                                    tag_size).expand(\n",
        "            batch_size, tag_size, tag_size)\n",
        "        _, last_bp = torch.max(last_values, 1)\n",
        "        pad_zero = autograd.Variable(torch.zeros(batch_size, tag_size)).long()\n",
        "        if self.gpu:\n",
        "            pad_zero = pad_zero.cuda()\n",
        "        back_points.append(pad_zero)\n",
        "        back_points = torch.cat(back_points).view(seq_len, batch_size, tag_size)\n",
        "\n",
        "        ## select end ids in STOP_TAG\n",
        "        pointer = last_bp[:, STOP_TAG]\n",
        "        insert_last = pointer.contiguous().view(batch_size, 1, 1).expand(batch_size, 1, tag_size)\n",
        "        back_points = back_points.transpose(1, 0).contiguous()\n",
        "        ## move the end ids(expand to tag_size) to the corresponding position of back_points to replace the 0 values\n",
        "        # print \"lp:\",last_position\n",
        "        # print \"il:\",insert_last\n",
        "        back_points.scatter_(1, last_position, insert_last)\n",
        "        # print \"bp:\",back_points\n",
        "        # exit(0)\n",
        "        back_points = back_points.transpose(1, 0).contiguous()\n",
        "        ## decode from the end, padded position ids are 0, which will be filtered if following evaluation\n",
        "        decode_idx = autograd.Variable(torch.LongTensor(seq_len, batch_size))\n",
        "        if self.gpu:\n",
        "            decode_idx = decode_idx.cuda()\n",
        "        decode_idx[-1] = pointer.detach()\n",
        "        for idx in range(len(back_points) - 2, -1, -1):\n",
        "            pointer = torch.gather(back_points[idx], 1, pointer.contiguous().view(batch_size, 1))\n",
        "            decode_idx[idx] = pointer.detach().view(batch_size)\n",
        "        path_score = None\n",
        "        decode_idx = decode_idx.transpose(1, 0)\n",
        "        return path_score, decode_idx\n",
        "\n",
        "    def _score_sentence(self, scores, mask, tags):\n",
        "        \"\"\"\n",
        "            input:\n",
        "                scores: variable (seq_len, batch, tag_size, tag_size)\n",
        "                mask: (batch, seq_len)\n",
        "                tags: tensor  (batch, seq_len)\n",
        "            output:\n",
        "                score: sum of score for gold sequences within whole batch\n",
        "        \"\"\"\n",
        "        # Gives the score of a provided tag sequence\n",
        "        batch_size = scores.size(1)\n",
        "        seq_len = scores.size(0)\n",
        "        tag_size = scores.size(2)\n",
        "        ## convert tag value into a new format, recorded label bigram information to index\n",
        "        new_tags = autograd.Variable(torch.LongTensor(batch_size, seq_len))\n",
        "        if self.gpu:\n",
        "            new_tags = new_tags.cuda()\n",
        "        for idx in range(seq_len):\n",
        "            if idx == 0:\n",
        "                ## start -> first score\n",
        "                new_tags[:, 0] = (tag_size - 2) * tag_size + tags[:, 0]\n",
        "\n",
        "            else:\n",
        "                new_tags[:, idx] = tags[:, idx - 1] * tag_size + tags[:, idx]\n",
        "\n",
        "        ## transition for label to STOP_TAG\n",
        "        end_transition = self.transitions[:, STOP_TAG].contiguous().view(1, tag_size).expand(batch_size, tag_size)\n",
        "        ## length for batch,  last word position = length - 1\n",
        "        length_mask = torch.sum(mask.long(), dim=1).view(batch_size, 1).long()\n",
        "        ## index the label id of last word\n",
        "        end_ids = torch.gather(tags, 1, length_mask - 1)\n",
        "\n",
        "        ## index the transition score for end_id to STOP_TAG\n",
        "        end_energy = torch.gather(end_transition, 1, end_ids)\n",
        "\n",
        "        ## convert tag as (seq_len, batch_size, 1)\n",
        "        new_tags = new_tags.transpose(1, 0).contiguous().view(seq_len, batch_size, 1)\n",
        "        ### need convert tags id to search from 400 positions of scores\n",
        "        tg_energy = torch.gather(scores.view(seq_len, batch_size, -1), 2, new_tags).view(seq_len,\n",
        "                                                                                         batch_size)  # seq_len * bat_size\n",
        "        ## mask transpose to (seq_len, batch_size)\n",
        "        tg_energy = tg_energy.masked_select(mask.transpose(1, 0))\n",
        "\n",
        "        # ## calculate the score from START_TAG to first label\n",
        "        # start_transition = self.transitions[START_TAG,:].view(1, tag_size).expand(batch_size, tag_size)\n",
        "        # start_energy = torch.gather(start_transition, 1, tags[0,:])\n",
        "\n",
        "        ## add all score together\n",
        "        # gold_score = start_energy.sum() + tg_energy.sum() + end_energy.sum()\n",
        "        gold_score = tg_energy.sum() + end_energy.sum()\n",
        "        return gold_score\n",
        "\n",
        "    def neg_log_likelihood_loss(self, feats, mask, tags):\n",
        "        # nonegative log likelihood\n",
        "        batch_size = feats.size(0)\n",
        "        forward_score, scores = self._calculate_PZ(feats, mask)\n",
        "        gold_score = self._score_sentence(scores, mask, tags)\n",
        "        # print \"batch, f:\", forward_score.data[0], \" g:\", gold_score.data[0], \" dis:\", forward_score.data[0] - gold_score.data[0]\n",
        "        # exit(0)\n",
        "        return forward_score - gold_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9f45FZulU1O"
      },
      "source": [
        "## Build Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3m1nwCS3lU1P"
      },
      "outputs": [],
      "source": [
        "class NERModel(pl.LightningModule):\n",
        "    \"\"\"\n",
        "    if you will you NLLLoss then you have to use log_softmax in forward else use CrossEntropy\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, word_emb_dim, hidden_dim, n_tags, alphabet_size, char_embedding_dim, char_hidden_dim,\n",
        "                learning_rate, dropout, bidirectional = False, n_layers = 1,\n",
        "                 use_pretrained = True, use_crf = True, use_gpu = True, use_char = True):\n",
        "        super().__init__()\n",
        "        self.use_crf = use_crf\n",
        "        self.crf = CRF(tagset_size= n_tags, gpu= use_gpu)\n",
        "        self.use_char = use_char\n",
        "        self.char_feature = CharCNN(alphabet_size, char_embedding_dim, char_hidden_dim, dropout)\n",
        "        self.input_dim = word_emb_dim\n",
        "        self.learning_rate = learning_rate\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "        if self.use_char:\n",
        "            self.input_dim += char_hidden_dim\n",
        "\n",
        "        # metrics\n",
        "        self.train_f1 = []\n",
        "        self.val_f1 = []\n",
        "        self.val_loss = []\n",
        "        self.test_f1 =[]\n",
        "        self.test_precision = []\n",
        "        self.test_recall = []\n",
        "\n",
        "        ## define loss\n",
        "        if self.use_crf:\n",
        "            self.loss_fn = self.crf.neg_log_likelihood_loss\n",
        "        else:\n",
        "            self.loss_fn = nn.CrossEntropyLoss(ignore_index=PAD_ID)\n",
        "\n",
        "        ## embedding layers\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim= word_emb_dim, padding_idx= PAD_ID)\n",
        "        if use_pretrained:\n",
        "            self.embedding.weight.data.copy_(weights)\n",
        "        else:\n",
        "            self.embedding.weight.data.copy_(torch.from_numpy(self.random_embedding(vocab_size, word_emb_dim)))\n",
        "\n",
        "        ## lstm layer\n",
        "        self.lstm = nn.LSTM(self.input_dim, hidden_dim, batch_first=True, bidirectional=bidirectional, dropout = dropout, num_layers = n_layers)\n",
        "\n",
        "        ## last layer\n",
        "        if self.use_crf:\n",
        "            self.hidden2tag = nn.Linear(hidden_dim * 2, n_tags + 2)\n",
        "        else:\n",
        "            self.hidden2tag = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, n_tags)\n",
        "\n",
        "        ## other layer\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def random_embedding(self, vocab_size, embedding_dim):\n",
        "        pretrain_emb = np.empty([vocab_size, embedding_dim])\n",
        "        scale = np.sqrt(3.0 / embedding_dim)\n",
        "        for index in range(1, vocab_size):\n",
        "            pretrain_emb[index, :] = np.random.uniform(-scale, scale, [1, embedding_dim])\n",
        "        return pretrain_emb\n",
        "\n",
        "    def forward(self, sent, char_inputs, lengths, verbose = False):\n",
        "\n",
        "        ## layers\n",
        "        word_embedding = self.embedding(sent)\n",
        "        # print(f\"word_embedding shape : {word_embedding.shape}\")\n",
        "        # word_embedding : [batch size, seq_len, emb dim]\n",
        "\n",
        "        word_list = [word_embedding]\n",
        "        if self.use_char:\n",
        "            char_features = self.char_feature(char_inputs)\n",
        "            # print(f\"char_features shape : {char_features.shape}\")\n",
        "            word_list.append(char_features)\n",
        "        embedded = torch.cat(word_list, 2)\n",
        "        # print(f\"final embedding shape : {embedded.shape}\")\n",
        "\n",
        "\n",
        "        packed_input = nn.utils.rnn.pack_padded_sequence(embedded, lengths.to('cpu'), batch_first = True, enforce_sorted = False)\n",
        "        x, xlengths = nn.utils.rnn.pad_packed_sequence(packed_input, batch_first = True)\n",
        "\n",
        "        output, (hidden, cell) = self.lstm(x)\n",
        "        output = self.dropout(output)\n",
        "        logits = self.hidden2tag(output)\n",
        "\n",
        "        if self.use_crf:\n",
        "            logits = logits\n",
        "        else:\n",
        "            logits = logits.permute(0,2,1)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Sent : {sent.shape}\")\n",
        "            print(f'length : {lengths.shape}')\n",
        "            print(f'x : {x.shape}')\n",
        "            print(f'xlengths : {xlengths.shape}')\n",
        "            print(f'embedded : {embedded.shape}')\n",
        "            print(f'output : {output.shape}')\n",
        "            print(f'hidden : {hidden.shape}')\n",
        "            print(f'cell : {cell.shape}')\n",
        "            print(f'logits : {logits.shape}')\n",
        "\n",
        "        return logits\n",
        "\n",
        "    def calculate_metrics(self, y_true, y_pred, mask):\n",
        "\n",
        "        y_true = y_true  * mask\n",
        "        y_pred = y_pred * mask\n",
        "\n",
        "        ## metrics\n",
        "        y_true = y_true.cpu().numpy().tolist()\n",
        "        y_pred = y_pred.cpu().numpy().tolist()\n",
        "        y_true_label = [[idx2tag[tag] for tag in sent_tag] for sent_tag in y_true]\n",
        "        y_pred_label = [[idx2tag[tag] for tag in sent_tag] for sent_tag in y_pred]\n",
        "\n",
        "        f1_score = metrics.f1_score(y_true_label, y_pred_label)\n",
        "        precision = metrics.precision_score(y_true_label, y_pred_label)\n",
        "        recall = metrics.recall_score(y_true_label, y_pred_label)\n",
        "        return f1_score, precision, recall\n",
        "\n",
        "    def _shared_step(self, batch):\n",
        "        sents, tags, char, lengths = batch['sent'], batch['tag'],batch['char'], batch['lengths']\n",
        "        mask = (tags != PAD_ID)\n",
        "        logits = self(sents, char, lengths)\n",
        "\n",
        "        if self.use_crf:\n",
        "            loss = self.loss_fn(logits, mask, tags)\n",
        "            _, preds = self.crf._viterbi_decode(logits, mask)\n",
        "        else:\n",
        "            loss = self.loss_fn(logits, tags)\n",
        "            _ , preds = torch.max(logits, dim = 1)\n",
        "\n",
        "        ## calculate metrics\n",
        "        f1_score, precision, recall = self.calculate_metrics(preds, tags, mask)\n",
        "        return loss, f1_score, precision, recall\n",
        "\n",
        "    def training_step(self, batch):\n",
        "        loss, f1_score, precision, recall = self._shared_step(batch)\n",
        "        self.train_f1.append(f1_score)\n",
        "        self.log_dict({\"train_loss\": loss, \"train_f1\": np.mean(self.train_f1)}, on_step = False, on_epoch = True, prog_bar=  True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        loss, f1_score, precision, recall = self._shared_step(batch)\n",
        "        self.val_f1.append(f1_score)\n",
        "        self.val_loss.append(loss.cpu().item())\n",
        "        self.log_dict({\"val_loss\": loss, \"val_f1\": np.mean(self.val_f1)}, on_step = False, on_epoch = True, prog_bar=  True)\n",
        "        return loss\n",
        "\n",
        "    def on_training_epoch_end(self):\n",
        "        self.train_f1 =[]\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        print(f'Epoch : {self.current_epoch} Loss : {np.mean(self.val_loss)} F1 : {np.mean(self.val_f1)}')\n",
        "        self.val_f1 =[]\n",
        "        self.val_loss = []\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = optim.Adam(self.parameters(), lr = self.learning_rate)\n",
        "        return optimizer\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        sents, tags, char, lengths = batch['sent'], batch['tag'], batch['char'], batch['lengths']\n",
        "        mask = (tags != PAD_ID)\n",
        "        logits = self(sents, char, lengths)\n",
        "\n",
        "        if self.use_crf:\n",
        "            _, preds = self.crf._viterbi_decode(logits, mask)\n",
        "        else:\n",
        "            _ , preds = torch.max(logits, dim = 1)\n",
        "\n",
        "        ## calculate metrics\n",
        "        f1_score, precision, recall = self.calculate_metrics(preds, tags, mask)\n",
        "        self.test_f1.append(f1_score)\n",
        "        self.test_precision.append(precision)\n",
        "        self.test_recall.append(recall)\n",
        "\n",
        "    def on_test_epoch_end(self):\n",
        "        print(f'F1 : {np.mean(self.test_f1)} Precision : {np.mean(self.test_precision)} Recall : {np.mean(self.test_recall)}')\n",
        "        self.test_f1 = []\n",
        "        self.test_precision = []\n",
        "        self.test_recall = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVBW_OlPlU1P",
        "outputId": "3d6e63d5-0b87-46cb-efd4-ad9e532b0a97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "build CRF...\n",
            "build char sequence feature extractor: CNN ...\n",
            "Sent : torch.Size([2, 30])\n",
            "length : torch.Size([2])\n",
            "x : torch.Size([2, 30, 150])\n",
            "xlengths : torch.Size([2])\n",
            "embedded : torch.Size([2, 30, 150])\n",
            "output : torch.Size([2, 30, 128])\n",
            "hidden : torch.Size([4, 2, 64])\n",
            "cell : torch.Size([4, 2, 64])\n",
            "logits : torch.Size([2, 30, 20])\n",
            "True label shape : torch.Size([2, 30])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(152.6577, grad_fn=<SubBackward0>)\n",
            "tensor([[10, 11, 10, 10, 10, 10, 10, 10, 10, 17, 11,  8, 10, 17, 11, 11, 11, 10,\n",
            "         17, 11, 10, 10, 10, 10,  0,  0,  0,  0,  0, 10],\n",
            "        [10, 11, 10, 17,  1, 17, 17, 11, 11, 11, 17, 10, 10, 10, 10, 10, 10, 17,\n",
            "         17, 10, 17,  1, 10, 10, 17, 10, 10, 11, 11, 10]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_15595/57801177.py:154: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at ../aten/src/ATen/native/TensorAdvancedIndexing.cpp:1646.)\n",
            "  cur_bp.masked_fill_(mask[idx].view(batch_size, 1).expand(batch_size, tag_size), 0)\n"
          ]
        }
      ],
      "source": [
        "model= NERModel(vocab_size = len(word2idx),\n",
        "                word_emb_dim = 100,\n",
        "                hidden_dim = 64,\n",
        "                n_tags = len(tag2idx),\n",
        "                alphabet_size = len(char2idx),\n",
        "                char_embedding_dim = 40,\n",
        "                char_hidden_dim = 50,\n",
        "                learning_rate = 1e-3,\n",
        "                dropout = 0.3,\n",
        "                bidirectional = True,\n",
        "                n_layers = 2,\n",
        "                use_pretrained= True,\n",
        "                use_crf= True\n",
        "                )\n",
        "\n",
        "\n",
        "logits = model(example['sent'], example['char'], example['lengths'], verbose = True)\n",
        "true_label = example['tag']\n",
        "print(f\"True label shape : {true_label.shape}\")\n",
        "\n",
        "model.crf.gpu = False\n",
        "mask = (true_label != PAD_ID)\n",
        "loss = model.loss_fn(logits, mask, true_label)\n",
        "print(loss)\n",
        "\n",
        "scores, tag_seq = model.crf._viterbi_decode(logits, mask)\n",
        "print(tag_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtLhPAQklU1Q",
        "outputId": "3b5e208b-0469-46f6-d7e7-f9962fb039fa",
        "colab": {
          "referenced_widgets": [
            "d0fac0312bf0438dbe07ca99c3e988fb",
            "dea85ce41be745209b1def6457b55d57",
            "5035403c090b40628978f0b6375f3ffa",
            "35027aca0db54dcf99157772028318e5",
            "c054896452df42868903982e5fd41cdc",
            "add7ae25ef6c496392da8a1a986b6d53",
            "847726f6e68d424e96a00e1b7659920d"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name         | Type      | Params\n",
            "-------------------------------------------\n",
            "0 | crf          | CRF       | 400   \n",
            "1 | char_feature | CharCNN   | 10.1 K\n",
            "2 | embedding    | Embedding | 3.5 M \n",
            "3 | lstm         | LSTM      | 209 K \n",
            "4 | hidden2tag   | Linear    | 2.6 K \n",
            "5 | relu         | ReLU      | 0     \n",
            "6 | dropout      | Dropout   | 0     \n",
            "-------------------------------------------\n",
            "3.7 M     Trainable params\n",
            "0         Non-trainable params\n",
            "3.7 M     Total params\n",
            "14.964    Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "build CRF...\n",
            "build char sequence feature extractor: CNN ...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d0fac0312bf0438dbe07ca99c3e988fb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_15595/57801177.py:154: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at ../aten/src/ATen/native/cuda/Indexing.cu:1435.)\n",
            "  cur_bp.masked_fill_(mask[idx].view(batch_size, 1).expand(batch_size, tag_size), 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 0 Loss : 1977.39111328125 F1 : 0.21277208848694418\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dea85ce41be745209b1def6457b55d57",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5035403c090b40628978f0b6375f3ffa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 0 Loss : 75.39525065104166 F1 : 0.865051225934098\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "35027aca0db54dcf99157772028318e5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 1 Loss : 59.58696831597222 F1 : 0.8787261799297456\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c054896452df42868903982e5fd41cdc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 2 Loss : 55.23013237847222 F1 : 0.8810156471404489\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "add7ae25ef6c496392da8a1a986b6d53",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 3 Loss : 55.05238498263889 F1 : 0.8783849786793029\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "847726f6e68d424e96a00e1b7659920d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 4 Loss : 54.40173177083334 F1 : 0.8791902906857032\n"
          ]
        }
      ],
      "source": [
        "## Model Training\n",
        "model= NERModel(vocab_size = len(word2idx),\n",
        "                word_emb_dim = 100,\n",
        "                hidden_dim = 64,\n",
        "                n_tags = len(tag2idx),\n",
        "                alphabet_size = len(char2idx),\n",
        "                char_embedding_dim = 40,\n",
        "                char_hidden_dim = 50,\n",
        "                learning_rate = 1e-3,\n",
        "                dropout = 0.3,\n",
        "                bidirectional = True,\n",
        "                n_layers = 2,\n",
        "                use_pretrained= True,\n",
        "                use_crf= True,\n",
        "                use_char=True\n",
        "                )\n",
        "\n",
        "callbacks = pl.callbacks.ModelCheckpoint(dirpath = \"checkpoints_logs\",\n",
        "                                         filename = '{epoch}-{val_loss:.2f}-{val_f1:.2f}',\n",
        "                                          mode = \"min\",\n",
        "                                          monitor = \"val_loss\",\n",
        "                                          save_last = True,\n",
        "                                          save_top_k=-1)\n",
        "\n",
        "\n",
        "trainer = pl.Trainer(accelerator= \"gpu\",\n",
        "           max_epochs=5,\n",
        "           check_val_every_n_epoch = 1,\n",
        "           callbacks = [callbacks])\n",
        "\n",
        "trainer.fit(model, train_dl, val_dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gOtQvdplU1Q",
        "outputId": "7d6c5150-911c-4c54-f6f4-f2965c8d4bac",
        "colab": {
          "referenced_widgets": [
            "12569f62a6714165846cf5a1a2ed2340"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/home/saurabh/anaconda3/envs/lighting/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "12569f62a6714165846cf5a1a2ed2340",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Testing: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_15595/57801177.py:154: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at ../aten/src/ATen/native/cuda/Indexing.cu:1435.)\n",
            "  cur_bp.masked_fill_(mask[idx].view(batch_size, 1).expand(batch_size, tag_size), 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 : 0.8860281703349736 Precision : 0.8816257179809235 Recall : 0.89082280124986\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{}]"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## F1 : 0.8860281703349736 Precision : 0.8816257179809235 Recall : 0.89082280124986\n",
        "trainer.test(model, dataloaders= test_dl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CN9I9xw7lU1Q"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mglbHo5-lU1Q"
      },
      "outputs": [],
      "source": [
        "model = model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6EV_ijDlU1R",
        "outputId": "17f5df11-b4e8-4a2a-ac6d-5b1f6f264d0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 27]) torch.Size([1, 27, 11]) torch.Size([1])\n",
            "Chinese               -->  B-gpe --> B-gpe\n",
            "worker                -->  O     --> O    \n",
            "sews                  -->  O     --> O    \n",
            "clothing              -->  O     --> O    \n",
            "at                    -->  O     --> O    \n",
            "a                     -->  O     --> O    \n",
            "garment               -->  O     --> O    \n",
            "factory               -->  O     --> O    \n",
            "in                    -->  O     --> O    \n",
            "Beijing               -->  B-geo --> B-geo\n",
            "China                 -->  I-geo --> I-geo\n",
            "is                    -->  O     --> O    \n",
            "criticizing           -->  O     --> O    \n",
            "the                   -->  O     --> O    \n",
            "European              -->  B-org --> B-org\n",
            "Union                 -->  I-org --> I-org\n",
            "'s                    -->  O     --> O    \n",
            "decision              -->  O     --> O    \n",
            "to                    -->  O     --> O    \n",
            "investigate           -->  O     --> O    \n",
            "surging               -->  O     --> O    \n",
            "imports               -->  O     --> O    \n",
            "of                    -->  O     --> O    \n",
            "Chinese               -->  B-gpe --> B-gpe\n",
            "textile               -->  O     --> O    \n",
            "products              -->  O     --> O    \n",
            ".\n",
            "                    -->  O     --> O    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_15595/57801177.py:154: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at ../aten/src/ATen/native/TensorAdvancedIndexing.cpp:1646.)\n",
            "  cur_bp.masked_fill_(mask[idx].view(batch_size, 1).expand(batch_size, tag_size), 0)\n"
          ]
        }
      ],
      "source": [
        "def process_data(text):\n",
        "    text = text.strip().split(\" \")\n",
        "    lengths = len(text)\n",
        "    word_encoded = []\n",
        "    for w in text:\n",
        "        word_encoded.append(word2idx.get(w, PAD_ID))\n",
        "\n",
        "    text_tensor = torch.tensor(word_encoded).view(1, -1)\n",
        "    lengths = torch.tensor([lengths])\n",
        "\n",
        "    ## char\n",
        "    char = to_char_number(text)\n",
        "    char = [[torch.tensor(_id) for _id in _char_id] for _char_id in [char]]\n",
        "    char_tensor = pad_char(char)\n",
        "\n",
        "    return text_tensor, char_tensor, lengths\n",
        "\n",
        "\n",
        "i = random.choices(list(range(len(test_sents))))[0]\n",
        "text = test_sents[i]\n",
        "true_label = test_tags[i].strip().split(\" \")\n",
        "text_tensor, char_tensor, lengths = process_data(text)\n",
        "print(text_tensor.shape, char_tensor.shape, lengths.shape)\n",
        "\n",
        "logits = model(text_tensor, char_tensor, lengths)\n",
        "mask = torch.ones_like(text_tensor)\n",
        "\n",
        "model.crf.gpu = False\n",
        "_, preds = model.crf._viterbi_decode(logits, mask)\n",
        "\n",
        "preds = preds.numpy()[0]\n",
        "pred_labels = [idx2tag[p] for p in preds]\n",
        "\n",
        "for w, p, t in zip(text.split(\" \"), pred_labels, true_label):\n",
        "    print(f\"{w:<20}  -->  {p:<5} --> {t:<5}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "lighting",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}