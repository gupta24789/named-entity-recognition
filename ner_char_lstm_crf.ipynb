{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gupta24789/named-entity-recognition/blob/main/ner_char_lstm_crf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWZhIOmKQZRp"
      },
      "outputs": [],
      "source": [
        "# !wget https://nlp.stanford.edu/data/glove.6B.zip\n",
        "# !unzip glove.6B.zip -d embeddings/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkTmDM8jQZRs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MRn3aAaQZRt"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import itertools\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "from pprint import pprint\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchmetrics\n",
        "from torch import optim\n",
        "import torch.autograd as autograd\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from seqeval import metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTlfLirdQZRv"
      },
      "source": [
        "## Download Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h--Ca-bJQZRx"
      },
      "outputs": [],
      "source": [
        "# Path('data/train').mkdir(parents = True, exist_ok= True)\n",
        "# Path('data/val').mkdir(parents = True, exist_ok= True)\n",
        "# Path('data/test').mkdir(parents = True, exist_ok= True)\n",
        "\n",
        "# os.system(\"cd data/train && wget https://raw.githubusercontent.com/gupta24789/named-entity-recognition/main/data/train/sentences.txt\")\n",
        "# os.system(\"cd data/train && wget https://raw.githubusercontent.com/gupta24789/named-entity-recognition/main/data/train/labels.txt\")\n",
        "# os.system(\"cd data/val && wget https://raw.githubusercontent.com/gupta24789/named-entity-recognition/main/data/val/sentences.txt\")\n",
        "# os.system(\"cd data/val && wget https://raw.githubusercontent.com/gupta24789/named-entity-recognition/main/data/val/labels.txt\")\n",
        "# os.system(\"cd data/test && wget https://raw.githubusercontent.com/gupta24789/named-entity-recognition/main/data/test/sentences.txt\")\n",
        "# os.system(\"cd data/test && wget https://raw.githubusercontent.com/gupta24789/named-entity-recognition/main/data/test/labels.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ti45Ux_BQZRy"
      },
      "source": [
        "## Set Seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hq-l1V8MQZRy",
        "outputId": "9f6b7965-6a6a-46f0-9e93-434fc9b1d7ec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Seed set to 121\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "121"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "seed = 121\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "pl.seed_everything(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ptcrs2MdQZRz"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22TetYK8QZRz"
      },
      "outputs": [],
      "source": [
        "## train\n",
        "train_sents = open(\"data/train/sentences.txt\",\"r\").readlines()\n",
        "train_tags = open(\"data/train/labels.txt\",\"r\").readlines()\n",
        "## val\n",
        "val_sents = open(\"data/val/sentences.txt\",\"r\").readlines()\n",
        "val_tags = open(\"data/val/labels.txt\",\"r\").readlines()\n",
        "## test\n",
        "test_sents = open(\"data/test/sentences.txt\",\"r\").readlines()\n",
        "test_tags = open(\"data/test/labels.txt\",\"r\").readlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2TtBBdbQZR0",
        "outputId": "4840f395-0aff-4fca-8b9c-691214715f83"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .\\n',\n",
              " 'Families of soldiers killed in the conflict joined the protesters who carried banners with such slogans as \" Bush Number One Terrorist \" and \" Stop the Bombings . \"\\n']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_sents[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJzR7dBvQZR0",
        "outputId": "a729fc48-0030-4c32-e829-b70443a0c574"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['O O O O O O B-geo O O O O O B-geo O O O O O B-gpe O O O O O\\n',\n",
              " 'O O O O O O O O O O O O O O O O O O B-per O O O O O O O O O O O\\n']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_tags[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuQycFtaQZR0"
      },
      "outputs": [],
      "source": [
        "X_train = [sent.strip().split(\" \") for sent in train_sents]\n",
        "y_train = [tag.strip().split(\" \") for tag in train_tags]\n",
        "\n",
        "X_val = [sent.strip().split(\" \") for sent in val_sents]\n",
        "y_val = [tag.strip().split(\" \") for tag in val_tags]\n",
        "\n",
        "X_test = [sent.strip().split(\" \") for sent in test_sents]\n",
        "y_test = [tag.strip().split(\" \") for tag in test_tags]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmrcQv5TQZR1",
        "outputId": "64a65758-f800-4a73-db48-6fe857b531c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['Thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'London',\n",
            "  'to', 'protest', 'the', 'war', 'in', 'Iraq', 'and', 'demand', 'the',\n",
            "  'withdrawal', 'of', 'British', 'troops', 'from', 'that', 'country', '.'],\n",
            " ['Families', 'of', 'soldiers', 'killed', 'in', 'the', 'conflict', 'joined',\n",
            "  'the', 'protesters', 'who', 'carried', 'banners', 'with', 'such', 'slogans',\n",
            "  'as', '\"', 'Bush', 'Number', 'One', 'Terrorist', '\"', 'and', '\"', 'Stop',\n",
            "  'the', 'Bombings', '.', '\"']]\n"
          ]
        }
      ],
      "source": [
        "pprint((X_train[:2]), compact=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7vAKzMwQZR1",
        "outputId": "67e96106-537a-461c-e50a-a787e305da2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O',\n",
            "  'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']]\n"
          ]
        }
      ],
      "source": [
        "pprint(y_train[:1], compact=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsHw88xfQZR1"
      },
      "source": [
        "## Create Vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jt55NpiCQZR2",
        "outputId": "85e8fe19-3d14-4a66-e987-fe55a928be1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Char Vocab : 100\n"
          ]
        }
      ],
      "source": [
        "## char vocab\n",
        "special_words = ['__PAD__','__UNK__']\n",
        "char_vocab = list(set(itertools.chain.from_iterable(X_train + X_val + X_test)))\n",
        "char_vocab = list(set(itertools.chain.from_iterable([list(w) for w in char_vocab])))\n",
        "char_vocab = special_words + char_vocab\n",
        "print(f'Char Vocab : {len(char_vocab)}')\n",
        "\n",
        "char2idx = {char:i for i, char in enumerate(char_vocab)}\n",
        "idx2char = {i:char for char,i in char2idx.items()}\n",
        "\n",
        "CHAR_UNK_ID = char2idx['__UNK__']\n",
        "CHAR_PAD_ID = char2idx['__PAD__']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2bA6WYXQZR2",
        "outputId": "94ef79f5-7a12-4adf-8beb-59ed4afecde3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vocab size : 35180\n",
            "tags : 18\n",
            "{'B-art': 10,\n",
            " 'B-eve': 1,\n",
            " 'B-geo': 14,\n",
            " 'B-gpe': 8,\n",
            " 'B-nat': 15,\n",
            " 'B-org': 17,\n",
            " 'B-per': 12,\n",
            " 'B-tim': 2,\n",
            " 'I-art': 5,\n",
            " 'I-eve': 9,\n",
            " 'I-geo': 16,\n",
            " 'I-gpe': 7,\n",
            " 'I-nat': 11,\n",
            " 'I-org': 13,\n",
            " 'I-per': 6,\n",
            " 'I-tim': 4,\n",
            " 'O': 3,\n",
            " '__PAD__': 0}\n",
            "PAD ID : 0\n"
          ]
        }
      ],
      "source": [
        "special_words = ['__PAD__','__UNK__']\n",
        "vocab = list(set(itertools.chain.from_iterable(X_train + X_val + X_test)))\n",
        "vocab = special_words + vocab\n",
        "word2idx = {w:i for i,w in enumerate(vocab)}\n",
        "idx2word = {i:w for w,i in word2idx.items()}\n",
        "\n",
        "## TAGS\n",
        "tags = list(set(itertools.chain.from_iterable(y_train)))\n",
        "tags = ['__PAD__'] + tags\n",
        "tag2idx = {w:i for i,w in enumerate(tags)}\n",
        "idx2tag = {i:w for w,i in tag2idx.items()}\n",
        "\n",
        "\n",
        "print(f\"vocab size : {len(vocab)}\")\n",
        "print(f\"tags : {len(tag2idx)}\")\n",
        "pprint(tag2idx, compact=True)\n",
        "\n",
        "PAD_ID = word2idx['__PAD__']\n",
        "UNK_ID = word2idx['__UNK__']\n",
        "\n",
        "print(f\"PAD ID : {PAD_ID}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgdLXvenQZR2"
      },
      "source": [
        "## Encode sent & tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNl05J2mQZR2"
      },
      "outputs": [],
      "source": [
        "def to_sent_number(sent_list):\n",
        "    encoded = []\n",
        "    for w in sent_list:\n",
        "        encoded.append(word2idx.get(w, UNK_ID))\n",
        "    return encoded\n",
        "\n",
        "\n",
        "def to_tag_number(tag_list):\n",
        "    encoded = []\n",
        "    for tag in tag_list:\n",
        "        encoded.append(tag2idx[tag])\n",
        "    return encoded\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TlUty_5QZR3"
      },
      "outputs": [],
      "source": [
        "def to_char_number(sent_list):\n",
        "    seq_char_list = []\n",
        "    for word in sent_list:\n",
        "        char_list = list(word)\n",
        "        char_id = list()\n",
        "        for char in char_list:\n",
        "            char_id.append(char2idx.get(char, CHAR_UNK_ID))\n",
        "        seq_char_list.append(char_id)\n",
        "    return seq_char_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4nDSbS9QZR3"
      },
      "outputs": [],
      "source": [
        "X_train_encoded = [to_sent_number(sent) for sent in X_train]\n",
        "X_train_char_encoded = [to_char_number(sent) for sent in X_train]\n",
        "y_train_encoded = [to_tag_number(tags) for tags in y_train]\n",
        "\n",
        "X_val_encoded = [to_sent_number(sent) for sent in X_val]\n",
        "X_val_char_encoded = [to_char_number(sent) for sent in X_val]\n",
        "y_val_encoded = [to_tag_number(tags) for tags in y_val]\n",
        "\n",
        "X_test_encoded = [to_sent_number(sent) for sent in X_test]\n",
        "X_test_char_encoded = [to_char_number(sent) for sent in X_test]\n",
        "y_test_encoded = [to_tag_number(tags) for tags in y_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_inAvdLFQZR3",
        "outputId": "ac6ab37e-e8b3-4f0b-a038-267da1af3d1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[33310, 24860, 5335, 10800, 18229, 14130, 23898, 3316, 10469, 21081, 1959,\n",
            "  26865, 11063, 16187, 16721, 21081, 512, 24860, 5134, 6718, 23818, 30872,\n",
            "  31208, 13700],\n",
            " [26277, 24860, 25750, 18760, 26865, 21081, 25119, 929, 21081, 2960, 9586,\n",
            "  22833, 18919, 24136, 16845, 22997, 11629, 18016, 5771, 13250, 33204, 25971,\n",
            "  18016, 16187, 18016, 1152, 21081, 11259, 13700, 18016]]\n"
          ]
        }
      ],
      "source": [
        "pprint(X_train_encoded[:2], compact=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGFfy4HgQZR3",
        "outputId": "7fc68928-01a3-4681-c6ce-0661149f9830"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[[44, 75, 51, 37, 78, 33, 36, 28, 78], [51, 54],\n",
            "  [28, 85, 25, 51, 36, 78, 58, 19, 33, 58, 51, 19, 78], [75, 33, 43, 85],\n",
            "  [25, 33, 19, 11, 75, 85, 28], [58, 75, 19, 51, 37, 59, 75],\n",
            "  [50, 51, 36, 28, 51, 36], [58, 51], [26, 19, 51, 58, 85, 78, 58],\n",
            "  [58, 75, 85], [79, 33, 19], [29, 36], [38, 19, 33, 89], [33, 36, 28],\n",
            "  [28, 85, 25, 33, 36, 28], [58, 75, 85],\n",
            "  [79, 29, 58, 75, 28, 19, 33, 79, 33, 10], [51, 54],\n",
            "  [53, 19, 29, 58, 29, 78, 75], [58, 19, 51, 51, 26, 78], [54, 19, 51, 25],\n",
            "  [58, 75, 33, 58], [11, 51, 37, 36, 58, 19, 72], [48]],\n",
            " [[87, 33, 25, 29, 10, 29, 85, 78], [51, 54], [78, 51, 10, 28, 29, 85, 19, 78],\n",
            "  [82, 29, 10, 10, 85, 28], [29, 36], [58, 75, 85],\n",
            "  [11, 51, 36, 54, 10, 29, 11, 58], [17, 51, 29, 36, 85, 28], [58, 75, 85],\n",
            "  [26, 19, 51, 58, 85, 78, 58, 85, 19, 78], [79, 75, 51],\n",
            "  [11, 33, 19, 19, 29, 85, 28], [61, 33, 36, 36, 85, 19, 78], [79, 29, 58, 75],\n",
            "  [78, 37, 11, 75], [78, 10, 51, 59, 33, 36, 78], [33, 78], [32],\n",
            "  [53, 37, 78, 75], [70, 37, 25, 61, 85, 19], [94, 36, 85],\n",
            "  [44, 85, 19, 19, 51, 19, 29, 78, 58], [32], [33, 36, 28], [32],\n",
            "  [7, 58, 51, 26], [58, 75, 85], [53, 51, 25, 61, 29, 36, 59, 78], [48], [32]]]\n"
          ]
        }
      ],
      "source": [
        "pprint(X_train_char_encoded[:2], compact=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_Rzb-UOQZR4",
        "outputId": "32a9ab23-b2b5-41c5-83ff-74bbed154be1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[3, 3, 3, 3, 3, 3, 14, 3, 3, 3, 3, 3, 14, 3, 3, 3, 3, 3, 8, 3, 3, 3, 3, 3],\n",
            " [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 12, 3, 3, 3, 3, 3, 3, 3,\n",
            "  3, 3, 3, 3]]\n"
          ]
        }
      ],
      "source": [
        "pprint(y_train_encoded[:2], compact=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhZKNvLYQZR4"
      },
      "source": [
        "## Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3R8ewmuQZR4"
      },
      "outputs": [],
      "source": [
        "def pad_char(chars):\n",
        "    batch_size = len(chars)\n",
        "    max_seq_len = max(map(len, chars))\n",
        "    pad_chars = [chars[idx] + [[0]] * (max_seq_len - len(chars[idx])) for idx in range(len(chars))]\n",
        "    length_list = [list(map(len, pad_char)) for pad_char in pad_chars]\n",
        "    max_word_len = max(map(max, length_list))\n",
        "    char_seq_tensor = torch.zeros((batch_size, max_seq_len, max_word_len)).long()\n",
        "    char_seq_lengths = torch.LongTensor(length_list)\n",
        "    for idx, (seq, seqlen) in enumerate(zip(pad_chars, char_seq_lengths)):\n",
        "        for idy, (word, wordlen) in enumerate(zip(seq, seqlen)):\n",
        "            char_seq_tensor[idx, idy, :wordlen] = torch.LongTensor(word)\n",
        "\n",
        "    return char_seq_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FyzkbZmQZR4"
      },
      "outputs": [],
      "source": [
        "def custom_collate(batch):\n",
        "    sent = [torch.tensor(item[0]) for item in batch]\n",
        "    char_input = [item[1] for item in batch]\n",
        "    tag = [torch.tensor(item[2]) for item in batch]\n",
        "    lengths = torch.tensor([len(item[0]) for item in batch])\n",
        "\n",
        "    padded_sent = nn.utils.rnn.pad_sequence(sent, batch_first=True, padding_value=PAD_ID)\n",
        "    padded_tag = nn.utils.rnn.pad_sequence(tag, batch_first=True, padding_value=PAD_ID)\n",
        "    padded_char = pad_char(char_input)\n",
        "\n",
        "    batch = {\"sent\": padded_sent, \"tag\": padded_tag, \"char\": padded_char, \"lengths\": lengths}\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uiTiM4IAQZR5"
      },
      "outputs": [],
      "source": [
        "train_dl = DataLoader(list(zip(X_train_encoded,X_train_char_encoded, y_train_encoded)), batch_size = 2, shuffle = False, collate_fn = custom_collate )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99BXaFf4QZR5"
      },
      "outputs": [],
      "source": [
        "example = next(iter(train_dl))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-h_QFCWQZR5",
        "outputId": "c52ad40a-cea0-4070-cf99-bb2edb475fd8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([2, 30]),\n",
              " torch.Size([2, 30]),\n",
              " torch.Size([2, 30, 13]),\n",
              " torch.Size([2]))"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example['sent'].shape, example['tag'].shape,  example['char'].shape, example['lengths'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrJ8srmLQZR5",
        "outputId": "9e23f7a2-2345-42a1-9c6c-02d366aad321"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[33310, 24860,  5335, 10800, 18229, 14130, 23898,  3316, 10469, 21081,\n",
              "          1959, 26865, 11063, 16187, 16721, 21081,   512, 24860,  5134,  6718,\n",
              "         23818, 30872, 31208, 13700,     0,     0,     0,     0,     0,     0],\n",
              "        [26277, 24860, 25750, 18760, 26865, 21081, 25119,   929, 21081,  2960,\n",
              "          9586, 22833, 18919, 24136, 16845, 22997, 11629, 18016,  5771, 13250,\n",
              "         33204, 25971, 18016, 16187, 18016,  1152, 21081, 11259, 13700, 18016]])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example['sent']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzrqxIDIQZR5",
        "outputId": "1ca6f0f8-f8eb-4fe9-e67f-557576295796"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 3,  3,  3,  3,  3,  3, 14,  3,  3,  3,  3,  3, 14,  3,  3,  3,  3,  3,\n",
              "          8,  3,  3,  3,  3,  3,  0,  0,  0,  0,  0,  0],\n",
              "        [ 3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
              "         12,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3]])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example['tag']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8KAEJ83MQZR6",
        "outputId": "4a16281e-f584-49c9-b8e8-8b370588c605"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[44, 75, 51, 37, 78, 33, 36, 28, 78,  0,  0,  0,  0],\n",
              "         [51, 54,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [28, 85, 25, 51, 36, 78, 58, 19, 33, 58, 51, 19, 78],\n",
              "         [75, 33, 43, 85,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [25, 33, 19, 11, 75, 85, 28,  0,  0,  0,  0,  0,  0],\n",
              "         [58, 75, 19, 51, 37, 59, 75,  0,  0,  0,  0,  0,  0],\n",
              "         [50, 51, 36, 28, 51, 36,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [58, 51,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [26, 19, 51, 58, 85, 78, 58,  0,  0,  0,  0,  0,  0],\n",
              "         [58, 75, 85,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [79, 33, 19,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [29, 36,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [38, 19, 33, 89,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [33, 36, 28,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [28, 85, 25, 33, 36, 28,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [58, 75, 85,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [79, 29, 58, 75, 28, 19, 33, 79, 33, 10,  0,  0,  0],\n",
              "         [51, 54,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [53, 19, 29, 58, 29, 78, 75,  0,  0,  0,  0,  0,  0],\n",
              "         [58, 19, 51, 51, 26, 78,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [54, 19, 51, 25,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [58, 75, 33, 58,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [11, 51, 37, 36, 58, 19, 72,  0,  0,  0,  0,  0,  0],\n",
              "         [48,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
              "\n",
              "        [[87, 33, 25, 29, 10, 29, 85, 78,  0,  0,  0,  0,  0],\n",
              "         [51, 54,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [78, 51, 10, 28, 29, 85, 19, 78,  0,  0,  0,  0,  0],\n",
              "         [82, 29, 10, 10, 85, 28,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [29, 36,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [58, 75, 85,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [11, 51, 36, 54, 10, 29, 11, 58,  0,  0,  0,  0,  0],\n",
              "         [17, 51, 29, 36, 85, 28,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [58, 75, 85,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [26, 19, 51, 58, 85, 78, 58, 85, 19, 78,  0,  0,  0],\n",
              "         [79, 75, 51,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [11, 33, 19, 19, 29, 85, 28,  0,  0,  0,  0,  0,  0],\n",
              "         [61, 33, 36, 36, 85, 19, 78,  0,  0,  0,  0,  0,  0],\n",
              "         [79, 29, 58, 75,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [78, 37, 11, 75,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [78, 10, 51, 59, 33, 36, 78,  0,  0,  0,  0,  0,  0],\n",
              "         [33, 78,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [32,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [53, 37, 78, 75,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [70, 37, 25, 61, 85, 19,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [94, 36, 85,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [44, 85, 19, 19, 51, 19, 29, 78, 58,  0,  0,  0,  0],\n",
              "         [32,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [33, 36, 28,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [32,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [ 7, 58, 51, 26,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [58, 75, 85,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [53, 51, 25, 61, 29, 36, 59, 78,  0,  0,  0,  0,  0],\n",
              "         [48,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [32,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]]])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example['char']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-vQV_euQZR6",
        "outputId": "3dc30e45-c1e6-44d4-ed5e-39041a3279ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([24, 30])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example['lengths']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fiYLm2DcQZR6"
      },
      "outputs": [],
      "source": [
        "## dataloaders\n",
        "batch_size = 32\n",
        "train_dl = DataLoader(list(zip(X_train_encoded,X_train_char_encoded, y_train_encoded)), batch_size = batch_size, shuffle = True, collate_fn = custom_collate )\n",
        "val_dl = DataLoader(list(zip(X_val_encoded,X_val_char_encoded, y_val_encoded)), batch_size = batch_size, shuffle = False, collate_fn = custom_collate )\n",
        "test_dl = DataLoader(list(zip(X_test_encoded,X_test_char_encoded,y_test_encoded)), batch_size = batch_size, shuffle = False, collate_fn = custom_collate )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtfoY6TIQZR6"
      },
      "source": [
        "## Pretrained Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkdfYq-GQZR6",
        "outputId": "e676fea7-04cf-49c0-a7e1-f5de2955cefe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([35180, 100])"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Pretrained Vectors\n",
        "def load_pretrain_emb(filepath):\n",
        "    lines = open(filepath,\"r\").readlines()\n",
        "    embedd_dict = {}\n",
        "    for line in lines:\n",
        "        if len(line)>0:\n",
        "            tokens = line.strip().split(\" \")\n",
        "            word = tokens[0]\n",
        "            vec = tokens[1:]\n",
        "            vec = np.array(vec).astype(float)\n",
        "            embedd_dict[word]= vec\n",
        "\n",
        "    return embedd_dict\n",
        "\n",
        "def build_pretrain_embedding(filepath, vocab, emb_dim):\n",
        "    embedd_dict = load_pretrain_emb(filepath)\n",
        "\n",
        "    df_list = []\n",
        "\n",
        "    for w,i in vocab.items():\n",
        "        if w in embedd_dict:\n",
        "            df_list.append(torch.tensor(embedd_dict[w]))\n",
        "        elif w.lower() in embedd_dict:\n",
        "            df_list.append(embedd_dict[w.lower()])\n",
        "        else:\n",
        "            random_vec = np.random.normal(size = (emb_dim))\n",
        "            df_list.append(random_vec)\n",
        "\n",
        "\n",
        "    return torch.tensor(df_list)\n",
        "\n",
        "\n",
        "\n",
        "weights = build_pretrain_embedding(\"embeddings/glove.6B.100d.txt\", word2idx, emb_dim=100)\n",
        "weights.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dxk_FLZrQZR7"
      },
      "source": [
        "## CharCNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3C6OsAGpQZR7"
      },
      "outputs": [],
      "source": [
        "class CharCNN(nn.Module):\n",
        "    def __init__(self, alphabet_size, embedding_dim, hidden_dim, dropout):\n",
        "        super(CharCNN, self).__init__()\n",
        "        print(\"build char sequence feature extractor: CNN ...\")\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.char_drop = nn.Dropout(dropout)\n",
        "        self.char_embeddings = nn.Embedding(alphabet_size, embedding_dim, padding_idx= CHAR_PAD_ID)\n",
        "        self.char_embeddings.weight.data.copy_(torch.from_numpy(CharCNN.random_embedding(alphabet_size, embedding_dim)))\n",
        "        # self.char_cnn = nn.Conv1d(embedding_dim, self.hidden_dim, kernel_size=3, padding=1)\n",
        "        self.linear = nn.Linear(embedding_dim, hidden_dim)\n",
        "\n",
        "    @staticmethod\n",
        "    def random_embedding(vocab_size, embedding_dim):\n",
        "        pretrain_emb = np.empty([vocab_size, embedding_dim])\n",
        "        scale = np.sqrt(3.0 / embedding_dim)\n",
        "        for index in range(vocab_size):\n",
        "            pretrain_emb[index, :] = np.random.uniform(-scale, scale, [1, embedding_dim])\n",
        "        pretrain_emb[0, :] = np.zeros((1, embedding_dim))\n",
        "        return pretrain_emb\n",
        "\n",
        "    def forward(self, input):\n",
        "        batch_size = input.size(0)\n",
        "        char_embeds = self.char_drop(self.char_embeddings(input))\n",
        "        # char_embeds = char_embeds.transpose(2, 1).contiguous()\n",
        "        # char_embeds = torch.mean(char_embeds, dim = 2).permute(0,2,1)\n",
        "        # print(f\"char_embeds : {char_embeds.shape}\")\n",
        "        # char_out = self.char_cnn(char_embeds)\n",
        "        # char_out = F.max_pool1d(char_out, char_out.size(2)).contiguous().view(batch_size, -1)\n",
        "        char_out = torch.mean(char_embeds, dim = 2)\n",
        "        char_out = self.linear(char_out)\n",
        "        return char_out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TqFJ-cKQZR8"
      },
      "source": [
        "## CRF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOeHV6YBQZR8"
      },
      "outputs": [],
      "source": [
        "START_TAG = -2\n",
        "STOP_TAG = -1\n",
        "\n",
        "\n",
        "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
        "def log_sum_exp(vec, m_size):\n",
        "    \"\"\"\n",
        "    calculate log of exp sum\n",
        "    args:\n",
        "        vec (batch_size, vanishing_dim, hidden_dim) : input tensor\n",
        "        m_size : hidden_dim\n",
        "    return:\n",
        "        batch_size, hidden_dim\n",
        "    \"\"\"\n",
        "    _, idx = torch.max(vec, 1)  # B * 1 * M\n",
        "    max_score = torch.gather(vec, 1, idx.view(-1, 1, m_size)).view(-1, 1, m_size)  # B * M\n",
        "    return max_score.view(-1, m_size) + torch.log(torch.sum(torch.exp(vec - max_score.expand_as(vec)), 1)).view(-1,\n",
        "                                                                                                                m_size)  # B * M\n",
        "\n",
        "\n",
        "class CRF(nn.Module):\n",
        "\n",
        "    def __init__(self, tagset_size, gpu):\n",
        "        super(CRF, self).__init__()\n",
        "        print(\"build CRF...\")\n",
        "        self.gpu = gpu\n",
        "        # Matrix of transition parameters.  Entry i,j is the score of transitioning from i to j.\n",
        "        self.tagset_size = tagset_size\n",
        "        # # We add 2 here, because of START_TAG and STOP_TAG\n",
        "        # # transitions (f_tag_size, t_tag_size), transition value from f_tag to t_tag\n",
        "        init_transitions = torch.zeros(self.tagset_size + 2, self.tagset_size + 2)\n",
        "        init_transitions[:, START_TAG] = -10000.0\n",
        "        init_transitions[STOP_TAG, :] = -10000.0\n",
        "        init_transitions[:, 0] = -10000.0\n",
        "        init_transitions[0, :] = -10000.0\n",
        "        # if self.gpu:\n",
        "        #     init_transitions = init_transitions.cuda()\n",
        "        self.transitions = nn.Parameter(init_transitions)\n",
        "\n",
        "        # self.transitions = nn.Parameter(torch.Tensor(self.tagset_size+2, self.tagset_size+2))\n",
        "        # self.transitions.data.zero_()\n",
        "\n",
        "    def _calculate_PZ(self, feats, mask):\n",
        "        \"\"\"\n",
        "            input:\n",
        "                feats: (batch, seq_len, self.tag_size+2)\n",
        "                masks: (batch, seq_len)\n",
        "        \"\"\"\n",
        "        batch_size = feats.size(0)\n",
        "        seq_len = feats.size(1)\n",
        "        tag_size = feats.size(2)\n",
        "        # print feats.view(seq_len, tag_size)\n",
        "        assert (tag_size == self.tagset_size + 2)\n",
        "        mask = mask.transpose(1, 0).contiguous()\n",
        "        ins_num = seq_len * batch_size\n",
        "        ## be careful the view shape, it is .view(ins_num, 1, tag_size) but not .view(ins_num, tag_size, 1)\n",
        "        feats = feats.transpose(1, 0).contiguous().view(ins_num, 1, tag_size).expand(ins_num, tag_size, tag_size)\n",
        "        ## need to consider start\n",
        "        scores = feats + self.transitions.view(1, tag_size, tag_size).expand(ins_num, tag_size, tag_size)\n",
        "        scores = scores.view(seq_len, batch_size, tag_size, tag_size)\n",
        "        # build iter\n",
        "        seq_iter = enumerate(scores)\n",
        "        _, inivalues = next(seq_iter)  # bat_size * from_target_size * to_target_size\n",
        "        # only need start from start_tag\n",
        "        partition = inivalues[:, START_TAG, :].clone().view(batch_size, tag_size, 1)  # bat_size * to_target_size\n",
        "\n",
        "        ## add start score (from start to all tag, duplicate to batch_size)\n",
        "        # partition = partition + self.transitions[START_TAG,:].view(1, tag_size, 1).expand(batch_size, tag_size, 1)\n",
        "        # iter over last scores\n",
        "        for idx, cur_values in seq_iter:\n",
        "            # previous to_target is current from_target\n",
        "            # partition: previous results log(exp(from_target)), #(batch_size * from_target)\n",
        "            # cur_values: bat_size * from_target * to_target\n",
        "\n",
        "            cur_values = cur_values + partition.contiguous().view(batch_size, tag_size, 1).expand(batch_size, tag_size,\n",
        "                                                                                                  tag_size)\n",
        "            cur_partition = log_sum_exp(cur_values, tag_size)\n",
        "            # print cur_partition.data\n",
        "\n",
        "            # (bat_size * from_target * to_target) -> (bat_size * to_target)\n",
        "            # partition = utils.switch(partition, cur_partition, mask[idx].view(bat_size, 1).expand(bat_size, self.tagset_size)).view(bat_size, -1)\n",
        "            mask_idx = mask[idx, :].view(batch_size, 1).expand(batch_size, tag_size)\n",
        "\n",
        "            ## effective updated partition part, only keep the partition value of mask value = 1\n",
        "            masked_cur_partition = cur_partition.masked_select(mask_idx)\n",
        "            ## let mask_idx broadcastable, to disable warning\n",
        "            mask_idx = mask_idx.contiguous().view(batch_size, tag_size, 1)\n",
        "\n",
        "            ## replace the partition where the maskvalue=1, other partition value keeps the same\n",
        "            partition.masked_scatter_(mask_idx, masked_cur_partition)\n",
        "        # until the last state, add transition score for all partition (and do log_sum_exp) then select the value in STOP_TAG\n",
        "        cur_values = self.transitions.view(1, tag_size, tag_size).expand(batch_size, tag_size,\n",
        "                                                                         tag_size) + partition.contiguous().view(\n",
        "            batch_size, tag_size, 1).expand(batch_size, tag_size, tag_size)\n",
        "        cur_partition = log_sum_exp(cur_values, tag_size)\n",
        "        final_partition = cur_partition[:, STOP_TAG]\n",
        "        return final_partition.sum(), scores\n",
        "\n",
        "    def _viterbi_decode(self, feats, mask):\n",
        "        \"\"\"\n",
        "            input:\n",
        "                feats: (batch, seq_len, self.tag_size+2)\n",
        "                mask: (batch, seq_len)\n",
        "            output:\n",
        "                decode_idx: (batch, seq_len) decoded sequence\n",
        "                path_score: (batch, 1) corresponding score for each sequence (to be implementated)\n",
        "        \"\"\"\n",
        "        batch_size = feats.size(0)\n",
        "        seq_len = feats.size(1)\n",
        "        tag_size = feats.size(2)\n",
        "        assert (tag_size == self.tagset_size + 2)\n",
        "        ## calculate sentence length for each sentence\n",
        "        length_mask = torch.sum(mask.long(), dim=1).view(batch_size, 1).long()\n",
        "        ## mask to (seq_len, batch_size)\n",
        "        mask = mask.transpose(1, 0).contiguous()\n",
        "        ins_num = seq_len * batch_size\n",
        "        ## be careful the view shape, it is .view(ins_num, 1, tag_size) but not .view(ins_num, tag_size, 1)\n",
        "        feats = feats.transpose(1, 0).contiguous().view(ins_num, 1, tag_size).expand(ins_num, tag_size, tag_size)\n",
        "        ## need to consider start\n",
        "        scores = feats + self.transitions.view(1, tag_size, tag_size).expand(ins_num, tag_size, tag_size)\n",
        "        scores = scores.view(seq_len, batch_size, tag_size, tag_size)\n",
        "\n",
        "        # build iter\n",
        "        seq_iter = enumerate(scores)\n",
        "        ## record the position of best score\n",
        "        back_points = list()\n",
        "        partition_history = list()\n",
        "        ##  reverse mask (bug for mask = 1- mask, use this as alternative choice)\n",
        "        # mask = 1 + (-1)*mask\n",
        "        mask = (1 - mask.long()).byte()\n",
        "        _, inivalues = next(seq_iter)  # bat_size * from_target_size * to_target_size\n",
        "        # only need start from start_tag\n",
        "        partition = inivalues[:, START_TAG, :].clone().view(batch_size, tag_size)  # bat_size * to_target_size\n",
        "        # print \"init part:\",partition.size()\n",
        "        partition_history.append(partition)\n",
        "        # iter over last scores\n",
        "        for idx, cur_values in seq_iter:\n",
        "            # previous to_target is current from_target\n",
        "            # partition: previous results log(exp(from_target)), #(batch_size * from_target)\n",
        "            # cur_values: batch_size * from_target * to_target\n",
        "            cur_values = cur_values + partition.contiguous().view(batch_size, tag_size, 1).expand(batch_size, tag_size,\n",
        "                                                                                                  tag_size)\n",
        "            ## forscores, cur_bp = torch.max(cur_values[:,:-2,:], 1) # do not consider START_TAG/STOP_TAG\n",
        "            # print \"cur value:\", cur_values.size()\n",
        "            partition, cur_bp = torch.max(cur_values, 1)\n",
        "            # print \"partsize:\",partition.size()\n",
        "            # exit(0)\n",
        "            # print partition\n",
        "            # print cur_bp\n",
        "            # print \"one best, \",idx\n",
        "            partition_history.append(partition)\n",
        "            ## cur_bp: (batch_size, tag_size) max source score position in current tag\n",
        "            ## set padded label as 0, which will be filtered in post processing\n",
        "            cur_bp.masked_fill_(mask[idx].view(batch_size, 1).expand(batch_size, tag_size), 0)\n",
        "            back_points.append(cur_bp)\n",
        "        # exit(0)\n",
        "        ### add score to final STOP_TAG\n",
        "        partition_history = torch.cat(partition_history, 0).view(seq_len, batch_size, -1).transpose(1,\n",
        "                                                                                                    0).contiguous()  ## (batch_size, seq_len. tag_size)\n",
        "        ### get the last position for each setences, and select the last partitions using gather()\n",
        "        last_position = length_mask.view(batch_size, 1, 1).expand(batch_size, 1, tag_size) - 1\n",
        "        last_partition = torch.gather(partition_history, 1, last_position).view(batch_size, tag_size, 1)\n",
        "        ### calculate the score from last partition to end state (and then select the STOP_TAG from it)\n",
        "        last_values = last_partition.expand(batch_size, tag_size, tag_size) + self.transitions.view(1, tag_size,\n",
        "                                                                                                    tag_size).expand(\n",
        "            batch_size, tag_size, tag_size)\n",
        "        _, last_bp = torch.max(last_values, 1)\n",
        "        pad_zero = autograd.Variable(torch.zeros(batch_size, tag_size)).long()\n",
        "        if self.gpu:\n",
        "            pad_zero = pad_zero.cuda()\n",
        "        back_points.append(pad_zero)\n",
        "        back_points = torch.cat(back_points).view(seq_len, batch_size, tag_size)\n",
        "\n",
        "        ## select end ids in STOP_TAG\n",
        "        pointer = last_bp[:, STOP_TAG]\n",
        "        insert_last = pointer.contiguous().view(batch_size, 1, 1).expand(batch_size, 1, tag_size)\n",
        "        back_points = back_points.transpose(1, 0).contiguous()\n",
        "        ## move the end ids(expand to tag_size) to the corresponding position of back_points to replace the 0 values\n",
        "        # print \"lp:\",last_position\n",
        "        # print \"il:\",insert_last\n",
        "        back_points.scatter_(1, last_position, insert_last)\n",
        "        # print \"bp:\",back_points\n",
        "        # exit(0)\n",
        "        back_points = back_points.transpose(1, 0).contiguous()\n",
        "        ## decode from the end, padded position ids are 0, which will be filtered if following evaluation\n",
        "        decode_idx = autograd.Variable(torch.LongTensor(seq_len, batch_size))\n",
        "        if self.gpu:\n",
        "            decode_idx = decode_idx.cuda()\n",
        "        decode_idx[-1] = pointer.detach()\n",
        "        for idx in range(len(back_points) - 2, -1, -1):\n",
        "            pointer = torch.gather(back_points[idx], 1, pointer.contiguous().view(batch_size, 1))\n",
        "            decode_idx[idx] = pointer.detach().view(batch_size)\n",
        "        path_score = None\n",
        "        decode_idx = decode_idx.transpose(1, 0)\n",
        "        return path_score, decode_idx\n",
        "\n",
        "    def _score_sentence(self, scores, mask, tags):\n",
        "        \"\"\"\n",
        "            input:\n",
        "                scores: variable (seq_len, batch, tag_size, tag_size)\n",
        "                mask: (batch, seq_len)\n",
        "                tags: tensor  (batch, seq_len)\n",
        "            output:\n",
        "                score: sum of score for gold sequences within whole batch\n",
        "        \"\"\"\n",
        "        # Gives the score of a provided tag sequence\n",
        "        batch_size = scores.size(1)\n",
        "        seq_len = scores.size(0)\n",
        "        tag_size = scores.size(2)\n",
        "        ## convert tag value into a new format, recorded label bigram information to index\n",
        "        new_tags = autograd.Variable(torch.LongTensor(batch_size, seq_len))\n",
        "        if self.gpu:\n",
        "            new_tags = new_tags.cuda()\n",
        "        for idx in range(seq_len):\n",
        "            if idx == 0:\n",
        "                ## start -> first score\n",
        "                new_tags[:, 0] = (tag_size - 2) * tag_size + tags[:, 0]\n",
        "\n",
        "            else:\n",
        "                new_tags[:, idx] = tags[:, idx - 1] * tag_size + tags[:, idx]\n",
        "\n",
        "        ## transition for label to STOP_TAG\n",
        "        end_transition = self.transitions[:, STOP_TAG].contiguous().view(1, tag_size).expand(batch_size, tag_size)\n",
        "        ## length for batch,  last word position = length - 1\n",
        "        length_mask = torch.sum(mask.long(), dim=1).view(batch_size, 1).long()\n",
        "        ## index the label id of last word\n",
        "        end_ids = torch.gather(tags, 1, length_mask - 1)\n",
        "\n",
        "        ## index the transition score for end_id to STOP_TAG\n",
        "        end_energy = torch.gather(end_transition, 1, end_ids)\n",
        "\n",
        "        ## convert tag as (seq_len, batch_size, 1)\n",
        "        new_tags = new_tags.transpose(1, 0).contiguous().view(seq_len, batch_size, 1)\n",
        "        ### need convert tags id to search from 400 positions of scores\n",
        "        tg_energy = torch.gather(scores.view(seq_len, batch_size, -1), 2, new_tags).view(seq_len,\n",
        "                                                                                         batch_size)  # seq_len * bat_size\n",
        "        ## mask transpose to (seq_len, batch_size)\n",
        "        tg_energy = tg_energy.masked_select(mask.transpose(1, 0))\n",
        "\n",
        "        # ## calculate the score from START_TAG to first label\n",
        "        # start_transition = self.transitions[START_TAG,:].view(1, tag_size).expand(batch_size, tag_size)\n",
        "        # start_energy = torch.gather(start_transition, 1, tags[0,:])\n",
        "\n",
        "        ## add all score together\n",
        "        # gold_score = start_energy.sum() + tg_energy.sum() + end_energy.sum()\n",
        "        gold_score = tg_energy.sum() + end_energy.sum()\n",
        "        return gold_score\n",
        "\n",
        "    def neg_log_likelihood_loss(self, feats, mask, tags):\n",
        "        # nonegative log likelihood\n",
        "        batch_size = feats.size(0)\n",
        "        forward_score, scores = self._calculate_PZ(feats, mask)\n",
        "        gold_score = self._score_sentence(scores, mask, tags)\n",
        "        # print \"batch, f:\", forward_score.data[0], \" g:\", gold_score.data[0], \" dis:\", forward_score.data[0] - gold_score.data[0]\n",
        "        # exit(0)\n",
        "        return forward_score - gold_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAtY-wKGQZR-"
      },
      "source": [
        "## Build Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ne_YrvvmQZR-"
      },
      "outputs": [],
      "source": [
        "class NERModel(pl.LightningModule):\n",
        "    \"\"\"\n",
        "    if you will you NLLLoss then you have to use log_softmax in forward else use CrossEntropy\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, word_emb_dim, hidden_dim, n_tags, alphabet_size, char_embedding_dim, char_hidden_dim,\n",
        "                learning_rate, dropout, bidirectional = False, n_layers = 1,\n",
        "                 use_pretrained = True, use_crf = True, use_gpu = True, use_char = True):\n",
        "        super().__init__()\n",
        "        self.use_crf = use_crf\n",
        "        self.crf = CRF(tagset_size= n_tags, gpu= use_gpu)\n",
        "        self.use_char = use_char\n",
        "        self.char_feature = CharCNN(alphabet_size, char_embedding_dim, char_hidden_dim, dropout)\n",
        "        self.input_dim = word_emb_dim\n",
        "        self.learning_rate = learning_rate\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "        if self.use_char:\n",
        "            self.input_dim += char_hidden_dim\n",
        "\n",
        "        # metrics\n",
        "        self.train_f1 = []\n",
        "        self.val_f1 = []\n",
        "        self.val_loss = []\n",
        "        self.test_f1 =[]\n",
        "        self.test_precision = []\n",
        "        self.test_recall = []\n",
        "\n",
        "        ## define loss\n",
        "        if self.use_crf:\n",
        "            self.loss_fn = self.crf.neg_log_likelihood_loss\n",
        "        else:\n",
        "            self.loss_fn = nn.CrossEntropyLoss(ignore_index=PAD_ID)\n",
        "\n",
        "        ## embedding layers\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim= word_emb_dim, padding_idx= PAD_ID)\n",
        "        if use_pretrained:\n",
        "            self.embedding.weight.data.copy_(weights)\n",
        "        else:\n",
        "            self.embedding.weight.data.copy_(torch.from_numpy(self.random_embedding(vocab_size, word_emb_dim)))\n",
        "\n",
        "        ## lstm layer\n",
        "        self.lstm = nn.LSTM(self.input_dim, hidden_dim, batch_first=True, bidirectional=bidirectional, dropout = dropout, num_layers = n_layers)\n",
        "\n",
        "        ## last layer\n",
        "        if self.use_crf:\n",
        "            self.hidden2tag = nn.Linear(hidden_dim * 2, n_tags + 2)\n",
        "        else:\n",
        "            self.hidden2tag = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, n_tags)\n",
        "\n",
        "        ## other layer\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def random_embedding(self, vocab_size, embedding_dim):\n",
        "        pretrain_emb = np.empty([vocab_size, embedding_dim])\n",
        "        scale = np.sqrt(3.0 / embedding_dim)\n",
        "        for index in range(1, vocab_size):\n",
        "            pretrain_emb[index, :] = np.random.uniform(-scale, scale, [1, embedding_dim])\n",
        "        return pretrain_emb\n",
        "\n",
        "    def forward(self, sent, char_inputs, lengths, verbose = False):\n",
        "\n",
        "        ## layers\n",
        "        word_embedding = self.embedding(sent)\n",
        "        # print(f\"word_embedding shape : {word_embedding.shape}\")\n",
        "        # word_embedding : [batch size, seq_len, emb dim]\n",
        "\n",
        "        word_list = [word_embedding]\n",
        "        if self.use_char:\n",
        "            char_features = self.char_feature(char_inputs)\n",
        "            word_list.append(char_features)\n",
        "        embedded = torch.cat(word_list, 2)\n",
        "        # print(f\"final embedding shape : {embedded.shape}\")\n",
        "\n",
        "\n",
        "        packed_input = nn.utils.rnn.pack_padded_sequence(embedded, lengths.to('cpu'), batch_first = True, enforce_sorted = False)\n",
        "        x, xlengths = nn.utils.rnn.pad_packed_sequence(packed_input, batch_first = True)\n",
        "\n",
        "        output, (hidden, cell) = self.lstm(x)\n",
        "        output = self.dropout(output)\n",
        "        logits = self.hidden2tag(output)\n",
        "\n",
        "        if self.use_crf:\n",
        "            logits = logits\n",
        "        else:\n",
        "            logits = logits.permute(0,2,1)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Sent : {sent.shape}\")\n",
        "            print(f'length : {lengths.shape}')\n",
        "            print(f'x : {x.shape}')\n",
        "            print(f'xlengths : {xlengths.shape}')\n",
        "            print(f'embedded : {embedded.shape}')\n",
        "            print(f'output : {output.shape}')\n",
        "            print(f'hidden : {hidden.shape}')\n",
        "            print(f'cell : {cell.shape}')\n",
        "            print(f'logits : {logits.shape}')\n",
        "\n",
        "        return logits\n",
        "\n",
        "    def calculate_metrics(self, y_true, y_pred, mask):\n",
        "\n",
        "        y_true = y_true  * mask\n",
        "        y_pred = y_pred * mask\n",
        "\n",
        "        ## metrics\n",
        "        y_true = y_true.cpu().numpy().tolist()\n",
        "        y_pred = y_pred.cpu().numpy().tolist()\n",
        "        y_true_label = [[idx2tag[tag] for tag in sent_tag] for sent_tag in y_true]\n",
        "        y_pred_label = [[idx2tag[tag] for tag in sent_tag] for sent_tag in y_pred]\n",
        "\n",
        "        f1_score = metrics.f1_score(y_true_label, y_pred_label)\n",
        "        precision = metrics.precision_score(y_true_label, y_pred_label)\n",
        "        recall = metrics.recall_score(y_true_label, y_pred_label)\n",
        "        return f1_score, precision, recall\n",
        "\n",
        "    def _shared_step(self, batch):\n",
        "        sents, tags, char, lengths = batch['sent'], batch['tag'],batch['char'], batch['lengths']\n",
        "        mask = (tags != PAD_ID)\n",
        "        logits = self(sents, char, lengths)\n",
        "\n",
        "        if self.use_crf:\n",
        "            loss = self.loss_fn(logits, mask, tags)\n",
        "            _, preds = self.crf._viterbi_decode(logits, mask)\n",
        "        else:\n",
        "            loss = self.loss_fn(logits, tags)\n",
        "            _ , preds = torch.max(logits, dim = 1)\n",
        "\n",
        "        ## calculate metrics\n",
        "        f1_score, precision, recall = self.calculate_metrics(preds, tags, mask)\n",
        "        return loss, f1_score, precision, recall\n",
        "\n",
        "    def training_step(self, batch):\n",
        "        loss, f1_score, precision, recall = self._shared_step(batch)\n",
        "        self.train_f1.append(f1_score)\n",
        "        self.log_dict({\"train_loss\": loss, \"train_f1\": np.mean(self.train_f1)}, on_step = False, on_epoch = True, prog_bar=  True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        loss, f1_score, precision, recall = self._shared_step(batch)\n",
        "        self.val_f1.append(f1_score)\n",
        "        self.val_loss.append(loss.cpu().item())\n",
        "        self.log_dict({\"val_loss\": loss, \"val_f1\": np.mean(self.val_f1)}, on_step = False, on_epoch = True, prog_bar=  True)\n",
        "        return loss\n",
        "\n",
        "    def on_training_epoch_end(self):\n",
        "        self.train_f1 =[]\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        print(f'Epoch : {self.current_epoch} Loss : {np.mean(self.val_loss)} F1 : {np.mean(self.val_f1)}')\n",
        "        self.val_f1 =[]\n",
        "        self.val_loss = []\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = optim.Adam(self.parameters(), lr = self.learning_rate)\n",
        "        return optimizer\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        sents, tags, char, lengths = batch['sent'], batch['tag'], batch['char'], batch['lengths']\n",
        "        mask = (tags != PAD_ID)\n",
        "        logits = self(sents, char, lengths)\n",
        "\n",
        "        if self.use_crf:\n",
        "            _, preds = self.crf._viterbi_decode(logits, mask)\n",
        "        else:\n",
        "            _ , preds = torch.max(logits, dim = 1)\n",
        "\n",
        "        ## calculate metrics\n",
        "        f1_score, precision, recall = self.calculate_metrics(preds, tags, mask)\n",
        "        self.test_f1.append(f1_score)\n",
        "        self.test_precision.append(precision)\n",
        "        self.test_recall.append(recall)\n",
        "\n",
        "    def on_test_epoch_end(self):\n",
        "        print(f'F1 : {np.mean(self.test_f1)} Precision : {np.mean(self.test_precision)} Recall : {np.mean(self.test_recall)}')\n",
        "        self.test_f1 = []\n",
        "        self.test_precision = []\n",
        "        self.test_recall = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iYrkJwzQZR-"
      },
      "outputs": [],
      "source": [
        "# model= NERModel(vocab_size = len(word2idx),\n",
        "#                 word_emb_dim = 100,\n",
        "#                 hidden_dim = 64,\n",
        "#                 n_tags = len(tag2idx),\n",
        "#                 alphabet_size = len(char2idx),\n",
        "#                 char_embedding_dim = 40,\n",
        "#                 char_hidden_dim = 50,\n",
        "#                 learning_rate = 1e-3,\n",
        "#                 dropout = 0.3,\n",
        "#                 bidirectional = True,\n",
        "#                 n_layers = 2,\n",
        "#                 use_pretrained= True,\n",
        "#                 use_crf= True\n",
        "#                 )\n",
        "\n",
        "\n",
        "# logits = model(example['sent'], example['char'], example['lengths'], verbose = True)\n",
        "# true_label = example['tag']\n",
        "# print(f\"True label shape : {true_label.shape}\")\n",
        "\n",
        "# model.crf.gpu = False\n",
        "# mask = (true_label != PAD_ID)\n",
        "# loss = model.loss_fn(logits, mask, true_label)\n",
        "# print(loss)\n",
        "\n",
        "# scores, tag_seq = model.crf._viterbi_decode(logits, mask)\n",
        "# print(tag_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uR5TlRzjQZR_",
        "outputId": "2fbf1a55-3c1b-4d51-dab9-ec86609a25ce",
        "colab": {
          "referenced_widgets": [
            "a41b2c96b30a429386a36936ca762f82",
            "086ad04aa4fa4abc9d63d2b19205531e",
            "9db87491e02541a6a3ae5fae3e1eb6b9",
            "a634469e048b4e38bc021a13f4f70830",
            "d832652d3fa74fdd920dbdd38209e121",
            "1dd8e51e3009433eae8baaec77299d1c",
            "c9e88942dced49bb9cd182fad3640896"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "/home/saurabh/anaconda3/envs/lighting/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:639: Checkpoint directory /home/saurabh/mydata/checkpoints_logs exists and is not empty.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name         | Type      | Params\n",
            "-------------------------------------------\n",
            "0 | crf          | CRF       | 400   \n",
            "1 | char_feature | CharCNN   | 6.0 K \n",
            "2 | embedding    | Embedding | 3.5 M \n",
            "3 | lstm         | LSTM      | 209 K \n",
            "4 | hidden2tag   | Linear    | 2.6 K \n",
            "5 | relu         | ReLU      | 0     \n",
            "6 | dropout      | Dropout   | 0     \n",
            "-------------------------------------------\n",
            "3.7 M     Trainable params\n",
            "0         Non-trainable params\n",
            "3.7 M     Total params\n",
            "14.948    Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "build CRF...\n",
            "build char sequence feature extractor: CNN ...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a41b2c96b30a429386a36936ca762f82",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/saurabh/anaconda3/envs/lighting/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
            "/tmp/ipykernel_15117/57801177.py:154: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at ../aten/src/ATen/native/cuda/Indexing.cu:1435.)\n",
            "  cur_bp.masked_fill_(mask[idx].view(batch_size, 1).expand(batch_size, tag_size), 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/saurabh/anaconda3/envs/lighting/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 0 Loss : 2029.4188232421875 F1 : 0.11759074259074259\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "086ad04aa4fa4abc9d63d2b19205531e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9db87491e02541a6a3ae5fae3e1eb6b9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 0 Loss : 69.60270399305556 F1 : 0.8696362915523735\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a634469e048b4e38bc021a13f4f70830",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 1 Loss : 58.025661892361114 F1 : 0.876385727250741\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d832652d3fa74fdd920dbdd38209e121",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 2 Loss : 52.52622178819445 F1 : 0.8808323863121444\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1dd8e51e3009433eae8baaec77299d1c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 3 Loss : 49.305659722222224 F1 : 0.8860889184786327\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c9e88942dced49bb9cd182fad3640896",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 4 Loss : 49.89532552083333 F1 : 0.88397360896727\n"
          ]
        }
      ],
      "source": [
        "## Model Training\n",
        "model= NERModel(vocab_size = len(word2idx),\n",
        "                word_emb_dim = 100,\n",
        "                hidden_dim = 64,\n",
        "                n_tags = len(tag2idx),\n",
        "                alphabet_size = len(char2idx),\n",
        "                char_embedding_dim = 40,\n",
        "                char_hidden_dim = 50,\n",
        "                learning_rate = 1e-3,\n",
        "                dropout = 0.3,\n",
        "                bidirectional = True,\n",
        "                n_layers = 2,\n",
        "                use_pretrained= True,\n",
        "                use_crf= True,\n",
        "                use_char=True\n",
        "                )\n",
        "\n",
        "callbacks = pl.callbacks.ModelCheckpoint(dirpath = \"checkpoints_logs\",\n",
        "                                         filename = '{epoch}-{val_loss:.2f}-{val_f1:.2f}',\n",
        "                                          mode = \"min\",\n",
        "                                          monitor = \"val_loss\",\n",
        "                                          save_last = True,\n",
        "                                          save_top_k=-1)\n",
        "\n",
        "\n",
        "trainer = pl.Trainer(accelerator= \"gpu\",\n",
        "           max_epochs=5,\n",
        "           check_val_every_n_epoch = 1,\n",
        "           callbacks = [callbacks])\n",
        "\n",
        "trainer.fit(model, train_dl, val_dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYvUBZNvQZR_",
        "outputId": "84316ca2-69f8-4f8e-fa2a-67f953e34273",
        "colab": {
          "referenced_widgets": [
            "5c3a2e441b254a77bed06d40bbf62537"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c3a2e441b254a77bed06d40bbf62537",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Testing: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_15117/57801177.py:154: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at ../aten/src/ATen/native/cuda/Indexing.cu:1435.)\n",
            "  cur_bp.masked_fill_(mask[idx].view(batch_size, 1).expand(batch_size, tag_size), 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 : 0.8868604345604159 Precision : 0.886774525815462 Recall : 0.8872570023491803\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{}]"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## F1 : 0.8868604345604159 Precision : 0.886774525815462 Recall : 0.8872570023491803\n",
        "trainer.test(model, dataloaders= test_dl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Svsc9ceVQZSA"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_nqhkLZQZSA"
      },
      "outputs": [],
      "source": [
        "model = model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qje6nQuhQZSB",
        "outputId": "18e49ea8-0b76-4d19-ece8-0493e4636b05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 33]) torch.Size([1, 33, 10]) torch.Size([1])\n",
            "Rashid                -->  B-org --> B-per\n",
            "Abu                   -->  I-org --> I-per\n",
            "Shbak                 -->  I-org --> I-per\n",
            ",                     -->  O     --> O    \n",
            "a                     -->  O     --> O    \n",
            "senior                -->  O     --> O    \n",
            "security              -->  O     --> O    \n",
            "official              -->  O     --> O    \n",
            "said                  -->  O     --> O    \n",
            "Saturday              -->  B-tim --> B-tim\n",
            "the                   -->  O     --> O    \n",
            "measures              -->  O     --> O    \n",
            "include               -->  O     --> O    \n",
            "the                   -->  O     --> O    \n",
            "disbanding            -->  O     --> O    \n",
            "of                    -->  O     --> O    \n",
            "the                   -->  O     --> O    \n",
            "Department            -->  B-org --> B-org\n",
            "of                    -->  I-org --> I-org\n",
            "Protection            -->  I-org --> I-org\n",
            "and                   -->  I-org --> I-org\n",
            "Security              -->  I-org --> I-org\n",
            ",                     -->  O     --> O    \n",
            "a                     -->  O     --> O    \n",
            "group                 -->  O     --> O    \n",
            "Gazans                -->  B-org --> O    \n",
            "have                  -->  O     --> O    \n",
            "nicknamed             -->  O     --> O    \n",
            "\"                     -->  O     --> O    \n",
            "death                 -->  O     --> O    \n",
            "squad                 -->  O     --> O    \n",
            ".                     -->  O     --> O    \n",
            "\"\n",
            "                    -->  O     --> O    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_15117/57801177.py:154: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at ../aten/src/ATen/native/TensorAdvancedIndexing.cpp:1646.)\n",
            "  cur_bp.masked_fill_(mask[idx].view(batch_size, 1).expand(batch_size, tag_size), 0)\n"
          ]
        }
      ],
      "source": [
        "def process_data(text):\n",
        "    text = text.strip().split(\" \")\n",
        "    lengths = len(text)\n",
        "    word_encoded = []\n",
        "    for w in text:\n",
        "        word_encoded.append(word2idx.get(w, PAD_ID))\n",
        "\n",
        "    text_tensor = torch.tensor(word_encoded).view(1, -1)\n",
        "    lengths = torch.tensor([lengths])\n",
        "\n",
        "    ## char\n",
        "    char = to_char_number(text)\n",
        "    char = [[torch.tensor(_id) for _id in _char_id] for _char_id in [char]]\n",
        "    char_tensor = pad_char(char)\n",
        "\n",
        "    return text_tensor, char_tensor, lengths\n",
        "\n",
        "\n",
        "i = random.choices(list(range(len(test_sents))))[0]\n",
        "text = test_sents[i]\n",
        "true_label = test_tags[i].strip().split(\" \")\n",
        "text_tensor, char_tensor, lengths = process_data(text)\n",
        "print(text_tensor.shape, char_tensor.shape, lengths.shape)\n",
        "\n",
        "logits = model(text_tensor, char_tensor, lengths)\n",
        "mask = torch.ones_like(text_tensor)\n",
        "\n",
        "model.crf.gpu = False\n",
        "_, preds = model.crf._viterbi_decode(logits, mask)\n",
        "\n",
        "preds = preds.numpy()[0]\n",
        "pred_labels = [idx2tag[p] for p in preds]\n",
        "\n",
        "for w, p, t in zip(text.split(\" \"), pred_labels, true_label):\n",
        "    print(f\"{w:<20}  -->  {p:<5} --> {t:<5}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "lighting",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}